{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with big data on the cloud\n",
    "\n",
    "Processing steps:\n",
    "\n",
    "Workflow for the cloud computing practical:\n",
    "1. Search the ESA Copernicus Sentinel Data Hub for all available images over a region within a defined time period and low cloud cover\n",
    "2. Download all selected images into a data directory\n",
    "3. Convert all images into Geotiff files (retain only the 10 m resolution bands)\n",
    "4. Save quicklooks of all images\n",
    "5. Extract polygon statistics of NDVI as a time series from all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required Python packages:\n",
    "# Note: GDAL needs to be version 2.1.3\n",
    "# from Anaconda terminal type:\n",
    "#    conda install -c conda-forge gdal\n",
    "\n",
    "from collections import OrderedDict\n",
    "import gdal\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ogr\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "import osr\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import shutil\n",
    "from skimage import io, exposure\n",
    "import subprocess\n",
    "import sys\n",
    "gdal.UseExceptions()\n",
    "io.use_plugin('matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some directory names. Modify these to match your data directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up your directories for the satellite data\n",
    "rootdir = join(os.sep, 'home', 'heiko', 'sf_GY7709_Satellite_Data_Analysis_in_Python', 'practicals')\n",
    "# directory for downloading the Sentinel-2 granules\n",
    "downloaddir = join(rootdir, 'download') \n",
    "# directory for the tiff files we will make\n",
    "tiffdir = join(rootdir, 'tiff') \n",
    "# quicklook directory\n",
    "quickdir = join(rootdir, 'quicklooks') \n",
    "# output directory for statistics file and search results\n",
    "outdir = join(rootdir, 'outputs') \n",
    "\n",
    "# create the new directories, unless they already exist\n",
    "os.makedirs(downloaddir, exist_ok=True)\n",
    "os.makedirs(tiffdir, exist_ok=True)\n",
    "os.makedirs(quickdir, exist_ok=True)\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, you have to make a text file called \"sencredentials.txt\" with your login details for the ESA Copernicus Sentinel Hub. The file has two lines of text.\n",
    "Line 1: Your username\n",
    "Line 2: Your password\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download options and Data Hub search parameters\n",
    "ndown = 10 # number of scenes to be downloaded (in order of least cloud cover)\n",
    "shapefile = join(rootdir, 'p8area.shp') # ESRI Shapefile of the study area\n",
    "datefrom = '20190401' # start date for imagery search\n",
    "dateto   = '20190630' # end date for imagery search\n",
    "clouds = '[0 TO 10]' # range of acceptable cloud cover % for imagery search\n",
    "    # Note that later versions of the Sentinelsat package require this in the format: clouds = (0, 10) \n",
    "credentials = join(rootdir, 'sencredentials.txt')  # contains two lines of text with username and password\n",
    "\n",
    "# Filename options\n",
    "# VRT virtual raster stack of all image files\n",
    "vrtfile = \"mosaic.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a function for converting all Sentinel-2 images in a directory into tiff files. Retain only the 10 m resolution bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next block of code is a function that reads in the Sentinel-2 L2A (Level 2A) image obtained from the Copernicus Sentinel Data Hub.\n",
    "# Sentinel images can be obtained for free from this web site: https://scihub.copernicus.eu/dhus/#/home\n",
    "\n",
    "def s2tiff(indir, outdir, ID):\n",
    "    '''\n",
    "    indir = directory where the input files are located\n",
    "    outdir = directory where the tiff file will be written if it does not already exist\n",
    "    ID = a string giving the filename without file extension\n",
    "    '''\n",
    "    # list all files in input directory    \n",
    "    print('Files in directory ' + indir)\n",
    "    allfiles = [f for f in listdir(indir) if isfile(join(indir, f))]\n",
    "    for f in allfiles:\n",
    "        print(f)\n",
    "\n",
    "    # make a band selection\n",
    "    print('Band files to be included in tiff file:')    \n",
    "    bands = allfiles[1:5]\n",
    "    for f in bands:\n",
    "        print(f)\n",
    "\n",
    "    # build a command line command for GDAL to convert the files into 10 m resolution VRT format\n",
    "    vrtfile = join(outdir, ID + '_16Bit.vrt')\n",
    "    cmd = ['gdalbuildvrt', '-resolution', 'user', '-tr' ,'10', '10', '-separate', vrtfile]\n",
    "    for band in bands:\n",
    "        cmd.append(join(indir, band))\n",
    "\n",
    "    if not os.path.exists(vrtfile): # skip if the output file already exists\n",
    "        print('\\n')\n",
    "        print(' '.join(cmd))\n",
    "        print('\\n')\n",
    "        subprocess.run(cmd) # execute the command in the command line\n",
    "    else:\n",
    "        print(vrtfile,' already exists.\\n')\n",
    "    \n",
    "    # check whether the output directory already exists and create it if not\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # now build a command to translate the four band raster files into one geotiff file with 4 bands\n",
    "    tiffile = join(outdir, ID + '_16Bit.tif')\n",
    "    cmd = ['gdal_translate', '-of' ,'GTiff', vrtfile, tiffile]\n",
    "\n",
    "    if not os.path.exists(tiffile): # skip if the output file already exists\n",
    "        print(' '.join(cmd))\n",
    "        print('\\n')\n",
    "        subprocess.run(cmd) # execute it\n",
    "    else:\n",
    "        print(tiffile,' already exists.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a function for making one quicklook image in PNG format out of one or many TIFF files. The output file is smaller than the originals, i.e. not full resolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes one PNG quicklook file by mosaicking all tiff files in a list of filenames\n",
    "\n",
    "def quicklooks(tiffdir, infilelist, outdir, mosaicID, outsize):\n",
    "    '''\n",
    "    tiffdir = directory in which the files in infilelist are located\n",
    "    infilelist = list of filenames (full path not included) to be processed\n",
    "    outdir = directory where the PNG quicklook files will be saved\n",
    "    mosaicID = beginning of the file name of the output files to be created (full path)\n",
    "    outsize = percentage downscaling factor, e.g. 10 means 10% of xsize and 10% of ysize\n",
    "    '''\n",
    "\n",
    "    # make output filenames\n",
    "    vrtfile = join(outdir, mosaicID + \".vrt\")\n",
    "    quicklookfile = join(outdir, mosaicID + \".png\")\n",
    "\n",
    "    print(vrtfile)\n",
    "    print(quicklookfile)\n",
    "    \n",
    "    # save the list of file names to a text file foruse in the GDAL command\n",
    "    filelist = join(outdir, \"filelist.txt\") # make a file name\n",
    "    \n",
    "    print(filelist)\n",
    "\n",
    "    file1 = open(filelist,\"w\") # open file in write mode \n",
    "\n",
    "    for f in infilelist:\n",
    "        file1.write(join(tiffdir, f)) \n",
    "        file1.write(\"\\n\")\n",
    "        print(join(tiffdir, f))\n",
    "        print(os.path.exists(join(tiffdir, f)))\n",
    "    file1.close() \n",
    "\n",
    "    # make a quicklook classification mosaic of all granules in PNG format using GDAL\n",
    "    com = \"gdalbuildvrt -overwrite -input_file_list \" + filelist + \" \"+ vrtfile\n",
    "    print(com)\n",
    "    flag = os.system(com)\n",
    "    if flag == 0:\n",
    "        print('Created VRT file: ' + vrtfile)\n",
    "    else:\n",
    "        print('Error creating VRT file')\n",
    "\n",
    "    # Create a PNG quicklook, scaled from 0 - 255\n",
    "    com = \"gdal_translate -of PNG -ot Byte -scale -outsize \" + str(outsize) + \"% \" + \\\n",
    "        str(outsize) + \"% \" + vrtfile + \" \" + quicklookfile\n",
    "    print(com)\n",
    "    flag = os.system(com)\n",
    "    if flag == 0:\n",
    "        print('Created quicklook mosaic file: ' + quicklookfile)\n",
    "    else:\n",
    "        print('Error creating quicklook mosaic file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################################\n",
    "# MAIN SCRIPT\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# 1. Search the ESA Copernicus Sentinel Data Hub for all available images \n",
    "#    over a region within a defined time period and low cloud cover\n",
    "#######################################################################\n",
    "\n",
    "os.chdir(rootdir) # go to working directory\n",
    "\n",
    "# load user credentials for Sentinel Data Hub at ESA, i.e. read two lines of text with username and password\n",
    "with open(credentials) as f:\n",
    "    lines = f.readlines()\n",
    "username = lines[0].strip()\n",
    "password = lines[1].strip()\n",
    "f.close()\n",
    "\n",
    "# Define the API\n",
    "api = SentinelAPI(username, password, 'https://scihub.copernicus.eu/dhus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the shapefile into GeoJSON if not already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geojson file already exists: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/p8area.geojson\n"
     ]
    }
   ],
   "source": [
    "# convert the shapefile to geojson as required by the Sentinel Hub\n",
    "gjfile = shapefile.split(\".\")[0]+\".geojson\"\n",
    "\n",
    "# check whether it exists already, e.g. from a previous run, in that case skip this step\n",
    "if not os.path.exists(gjfile):\n",
    "    com = \"ogr2ogr -f GeoJSON -t_srs crs:84 \" + gjfile + \" \" + shapefile\n",
    "    flag = os.system(com)\n",
    "    if flag == 0:\n",
    "        print('Shapefile converted to Geojson format: ' + gjfile)\n",
    "    else:\n",
    "        print('Error converting shapefile to Geojson')\n",
    "\n",
    "else:\n",
    "    print('Geojson file already exists: ' + gjfile)\n",
    "\n",
    "# convert the geojson to wkt for the API search on the Sentinel Hub\n",
    "footprint = geojson_to_wkt(read_geojson(gjfile))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the ESA Sentinel data hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set query parameters and search the Sentinel data hub\n",
    "query_kwargs = {\n",
    "        'area': footprint,\n",
    "        'date': (datefrom, dateto),\n",
    "        'platformname': 'Sentinel-2',\n",
    "        'processinglevel': 'Level-2A',\n",
    "        'cloudcoverpercentage': clouds\n",
    "        }\n",
    "\n",
    "# search the Sentinel data hub API\n",
    "products = api.query(**query_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search resulted in 13 satellite images with 36 attributes.\n",
      "                                                                                  title  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_2...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_2...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_2...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_2...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_2...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_2...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_2...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_2...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_2...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_2...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  S2B_MSIL2A_20190420T112119_N0211_R037_T30UXD_2...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  S2B_MSIL2A_20190417T110629_N0211_R137_T30UYD_2...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  S2A_MSIL2A_20190512T110621_N0212_R137_T31UCU_2...   \n",
      "\n",
      "                                                                                   link  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "\n",
      "                                                                       link_alternative  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "\n",
      "                                                                              link_icon  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  https://scihub.copernicus.eu/dhus/odata/v1/Pro...   \n",
      "\n",
      "                                                                                summary  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  Date: 2019-05-24T10:56:29.024Z, Instrument: MS...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  Date: 2019-05-12T11:06:21.024Z, Instrument: MS...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  Date: 2019-06-29T11:21:19.024Z, Instrument: MS...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  Date: 2019-06-28T10:56:21.024Z, Instrument: MS...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  Date: 2019-06-03T10:56:29.024Z, Instrument: MS...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  Date: 2019-05-14T10:56:29.024Z, Instrument: MS...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  Date: 2019-05-24T10:56:29.024Z, Instrument: MS...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  Date: 2019-05-14T10:56:29.024Z, Instrument: MS...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  Date: 2019-05-24T10:56:29.024Z, Instrument: MS...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  Date: 2019-05-14T10:56:29.024Z, Instrument: MS...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  Date: 2019-04-20T11:21:19.024Z, Instrument: MS...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  Date: 2019-04-17T11:06:29.024Z, Instrument: MS...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  Date: 2019-05-12T11:06:21.024Z, Instrument: MS...   \n",
      "\n",
      "                                               beginposition  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c 2019-05-24 10:56:29.024   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1 2019-05-12 11:06:21.024   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c 2019-06-29 11:21:19.024   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd 2019-06-28 10:56:21.024   \n",
      "3661b627-0b92-4d4d-8691-33c294129443 2019-06-03 10:56:29.024   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095 2019-05-14 10:56:29.024   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2 2019-05-24 10:56:29.024   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895 2019-05-14 10:56:29.024   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366 2019-05-24 10:56:29.024   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce 2019-05-14 10:56:29.024   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14 2019-04-20 11:21:19.024   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3 2019-04-17 11:06:29.024   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd 2019-05-12 11:06:21.024   \n",
      "\n",
      "                                                 endposition  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c 2019-05-24 10:56:29.024   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1 2019-05-12 11:06:21.024   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c 2019-06-29 11:21:19.024   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd 2019-06-28 10:56:21.024   \n",
      "3661b627-0b92-4d4d-8691-33c294129443 2019-06-03 10:56:29.024   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095 2019-05-14 10:56:29.024   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2 2019-05-24 10:56:29.024   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895 2019-05-14 10:56:29.024   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366 2019-05-24 10:56:29.024   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce 2019-05-14 10:56:29.024   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14 2019-04-20 11:21:19.024   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3 2019-04-17 11:06:29.024   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd 2019-05-12 11:06:21.024   \n",
      "\n",
      "                                               ingestiondate  orbitnumber  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c 2019-05-24 17:57:35.868        11560   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1 2019-05-12 20:33:04.678        20297   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c 2019-06-30 05:07:55.799        12075   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd 2019-06-28 22:46:54.365        20969   \n",
      "3661b627-0b92-4d4d-8691-33c294129443 2019-06-03 23:40:06.003        11703   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095 2019-05-14 22:16:20.276        11417   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2 2019-05-24 18:22:32.905        11560   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895 2019-05-14 22:07:33.887        11417   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366 2019-05-24 18:04:13.964        11560   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce 2019-05-14 22:26:36.009        11417   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14 2019-04-20 18:53:32.727        11074   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3 2019-04-17 18:12:46.077        11031   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd 2019-05-12 20:18:49.498        20297   \n",
      "\n",
      "                                      relativeorbitnumber  ...  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c                   94  ...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1                  137  ...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c                   37  ...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd                   94  ...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443                   94  ...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095                   94  ...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2                   94  ...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895                   94  ...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366                   94  ...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce                   94  ...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14                   37  ...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3                  137  ...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd                  137  ...   \n",
      "\n",
      "                                      platformserialidentifier  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c               Sentinel-2B   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1               Sentinel-2A   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c               Sentinel-2B   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd               Sentinel-2A   \n",
      "3661b627-0b92-4d4d-8691-33c294129443               Sentinel-2B   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095               Sentinel-2B   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2               Sentinel-2B   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895               Sentinel-2B   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366               Sentinel-2B   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce               Sentinel-2B   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14               Sentinel-2B   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3               Sentinel-2B   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd               Sentinel-2A   \n",
      "\n",
      "                                      processingbaseline  processinglevel  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c               02.12         Level-2A   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1               02.12         Level-2A   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c               02.12         Level-2A   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd               02.12         Level-2A   \n",
      "3661b627-0b92-4d4d-8691-33c294129443               02.12         Level-2A   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095               02.12         Level-2A   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2               02.12         Level-2A   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895               02.12         Level-2A   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366               02.12         Level-2A   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce               02.12         Level-2A   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14               02.11         Level-2A   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3               02.11         Level-2A   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd               02.12         Level-2A   \n",
      "\n",
      "                                      producttype  platformname        size  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c      S2MSI2A    Sentinel-2   609.88 MB   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1      S2MSI2A    Sentinel-2   793.32 MB   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c      S2MSI2A    Sentinel-2   772.41 MB   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd      S2MSI2A    Sentinel-2   116.58 MB   \n",
      "3661b627-0b92-4d4d-8691-33c294129443      S2MSI2A    Sentinel-2   595.23 MB   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095      S2MSI2A    Sentinel-2   123.60 MB   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2      S2MSI2A    Sentinel-2  1017.26 MB   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895      S2MSI2A    Sentinel-2  1005.67 MB   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366      S2MSI2A    Sentinel-2  1023.78 MB   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce      S2MSI2A    Sentinel-2  1014.14 MB   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14      S2MSI2A    Sentinel-2   756.77 MB   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3      S2MSI2A    Sentinel-2     1.03 GB   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd      S2MSI2A    Sentinel-2     1.02 GB   \n",
      "\n",
      "                                                                               filename  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_2...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_2...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_2...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_2...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_2...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_2...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_2...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_2...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_2...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_2...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  S2B_MSIL2A_20190420T112119_N0211_R037_T30UXD_2...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  S2B_MSIL2A_20190417T110629_N0211_R137_T30UYD_2...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  S2A_MSIL2A_20190512T110621_N0212_R137_T31UCU_2...   \n",
      "\n",
      "                                                                   level1cpdiidentifier  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  S2B_OPER_MSI_L1C_TL_SGS__20190524T130641_A0115...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  S2A_OPER_MSI_L1C_TL_MTI__20190512T114532_A0202...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  S2B_OPER_MSI_L1C_TL_EPAE_20190629T123210_A0120...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  S2A_OPER_MSI_L1C_TL_MPS__20190628T131710_A0209...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  S2B_OPER_MSI_L1C_TL_MPS__20190603T131528_A0117...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  S2B_OPER_MSI_L1C_TL_EPAE_20190514T120915_A0114...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  S2B_OPER_MSI_L1C_TL_SGS__20190524T130641_A0115...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  S2B_OPER_MSI_L1C_TL_EPAE_20190514T120915_A0114...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  S2B_OPER_MSI_L1C_TL_SGS__20190524T130641_A0115...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  S2B_OPER_MSI_L1C_TL_EPAE_20190514T120915_A0114...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  S2B_OPER_MSI_L1C_TL_SGS__20190420T132504_A0110...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  S2B_OPER_MSI_L1C_TL_SGS__20190417T131333_A0110...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  S2A_OPER_MSI_L1C_TL_MTI__20190512T114532_A0202...   \n",
      "\n",
      "                                                                             identifier  \\\n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_2...   \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_2...   \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_2...   \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_2...   \n",
      "3661b627-0b92-4d4d-8691-33c294129443  S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_2...   \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_2...   \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_2...   \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_2...   \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_2...   \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_2...   \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  S2B_MSIL2A_20190420T112119_N0211_R037_T30UXD_2...   \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  S2B_MSIL2A_20190417T110629_N0211_R137_T30UYD_2...   \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  S2A_MSIL2A_20190512T110621_N0212_R137_T31UCU_2...   \n",
      "\n",
      "                                                                      uuid  \n",
      "9ac92e71-7bde-4290-9a47-6d2492e3169c  9ac92e71-7bde-4290-9a47-6d2492e3169c  \n",
      "e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  e2543618-f3d1-42aa-ac9d-a7862bb5cfb1  \n",
      "35dc5311-271f-4d7c-808f-8ff8cc30fd5c  35dc5311-271f-4d7c-808f-8ff8cc30fd5c  \n",
      "851a43ec-a2e6-4104-9da7-62bda5f930bd  851a43ec-a2e6-4104-9da7-62bda5f930bd  \n",
      "3661b627-0b92-4d4d-8691-33c294129443  3661b627-0b92-4d4d-8691-33c294129443  \n",
      "dd9a1c69-f127-4356-8004-7e3f5ae95095  dd9a1c69-f127-4356-8004-7e3f5ae95095  \n",
      "934a618c-cb64-4c50-b1a5-6ea5670bb0a2  934a618c-cb64-4c50-b1a5-6ea5670bb0a2  \n",
      "4b06d488-fb3a-487c-8db4-3e63058ad895  4b06d488-fb3a-487c-8db4-3e63058ad895  \n",
      "f6814a1e-e092-4a0e-b865-4129f711f366  f6814a1e-e092-4a0e-b865-4129f711f366  \n",
      "0cc98e85-c1f4-4977-8b38-bb31f30b2cce  0cc98e85-c1f4-4977-8b38-bb31f30b2cce  \n",
      "84ee0fab-08fd-4629-b104-60f0b0caec14  84ee0fab-08fd-4629-b104-60f0b0caec14  \n",
      "f2bae5ce-97b8-4739-ad15-67b6700746e3  f2bae5ce-97b8-4739-ad15-67b6700746e3  \n",
      "17648827-6eda-4870-bf94-d6be57beb4dd  17648827-6eda-4870-bf94-d6be57beb4dd  \n",
      "\n",
      "[13 rows x 36 columns]\n",
      "Search results saved: searchresults_full.csv\n",
      "Download list saved: searchresults4download.csv\n",
      "Granule footprints saved: searchresultsfootprints.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heiko/anaconda3/envs/pyeo_env/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# convert list of products to Pandas DataFrame\n",
    "products_df = api.to_dataframe(products)\n",
    "print('Search resulted in '+str(products_df.shape[0])+' satellite images with '+\n",
    "      str(products_df.shape[1])+' attributes.')\n",
    "\n",
    "os.chdir(outdir) # set working direcory to directory for our text file outputs\n",
    "\n",
    "# sort the search results\n",
    "products_df_sorted = products_df.sort_values(['cloudcoverpercentage', 'ingestiondate'], ascending=[True, True])\n",
    "print(products_df_sorted)\n",
    "outfile = 'searchresults_full.csv'\n",
    "products_df_sorted.to_csv(outfile)\n",
    "print(\"Search results saved: \" + outfile)\n",
    "\n",
    "# limit to first Ndown products sorted by lowest cloud cover and earliest acquisition date\n",
    "products_df_n = products_df_sorted.head(ndown)\n",
    "outfile = 'searchresults4download.csv'\n",
    "products_df_n.to_csv(outfile)\n",
    "print(\"Download list saved: \" + outfile)\n",
    "\n",
    "# get the footprints of the selected scenes\n",
    "s2footprints = products_df_n.footprint\n",
    "outfile = 'searchresultsfootprints.csv'\n",
    "s2footprints.to_csv(outfile)\n",
    "print(\"Granule footprints saved: \" + outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data. This takes a long time if many images are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'products_df_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c45006cbe7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# download sorted and reduced products in order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts_df_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uuid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'products_df_n' is not defined"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# 2. Download all selected images into a data directory\n",
    "#######################################################################\n",
    "\n",
    "os.chdir(downloaddir) # set working direcory to download directory\n",
    "\n",
    "# download sorted and reduced products in order\n",
    "api.download_all(products_df_n['uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granule footprints saved as GeoJson: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/outputs/footprints.geojson\n"
     ]
    }
   ],
   "source": [
    "# save the footprints of the scenes marked for download together with their metadata in a Geojson file\n",
    "# first, run a new query to get the metadata for the selected scenes\n",
    "products_n = OrderedDict()\n",
    "for uuid in products_df_n['uuid']:\n",
    "    kw = query_kwargs.copy()\n",
    "    kw['uuid'] = uuid\n",
    "    pp = api.query(**kw)\n",
    "    products_n.update(pp)\n",
    "\n",
    "# then, write the footprints and metadata to a geojson file\n",
    "outfile = join(outdir, 'footprints.geojson')\n",
    "with open(outfile, 'w') as f:\n",
    "    json.dump(api.to_geojson(products_n), f)\n",
    "print(\"Granule footprints saved as GeoJson: \" + outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping file  1 :  S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  2 :  S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  3 :  S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  4 :  S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  5 :  S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  6 :  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  7 :  S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  8 :  S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  9 :  S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715_16Bit.tif  already exists.\n",
      "\n",
      "Unzipping file  10 :  S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.zip\n",
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/download/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135.SAFE/GRANULE/L2A_T30UXD_A012075_20190629T112256/IMG_DATA/R10m\n",
      "T30UXD_20190629T112119_AOT_10m.jp2\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "T30UXD_20190629T112119_TCI_10m.jp2\n",
      "T30UXD_20190629T112119_WVP_10m.jp2\n",
      "Band files to be included in tiff file:\n",
      "T30UXD_20190629T112119_B02_10m.jp2\n",
      "T30UXD_20190629T112119_B03_10m.jp2\n",
      "T30UXD_20190629T112119_B04_10m.jp2\n",
      "T30UXD_20190629T112119_B08_10m.jp2\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135_16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135_16Bit.tif  already exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# 3. Convert all images into Geotiff files (retain only the 10 m resolution bands)\n",
    "#######################################################################\n",
    "\n",
    "# set working direcory to download directory\n",
    "os.chdir(downloaddir)\n",
    "\n",
    "# get list of all zip files in the data directory\n",
    "allfiles = [f for f in listdir(downloaddir) if isfile(join(downloaddir, f))]\n",
    "\n",
    "# unzip all these files and convert the 10 m bands to Geotiff\n",
    "\n",
    "for x in range(len(allfiles)):\n",
    "\n",
    "    if allfiles[x].split(\".\")[1] == \"zip\":\n",
    "        \n",
    "        print(\"Unzipping file \", x+1, \": \", allfiles[x])\n",
    "        os.system(\"unzip \" + allfiles[x])\n",
    "\n",
    "        # in this directory are the Sentinel-2, 10 m resolution band files\n",
    "        \n",
    "        # extract *.SAFE subdirectory path, then GRANULE, then L2A_*, then IMG_DATA, then R10m\n",
    "        sceneID = allfiles[x].split(\".\")[0] # the first part of the directory name is the granule ID\n",
    "\n",
    "        # find *.SAFE subdirectory\n",
    "        dirlist = [d for d in listdir(downloaddir) if isdir(join(downloaddir, d))]\n",
    "        for y in range(len(dirlist)):\n",
    "            if dirlist[y].split(\".\")[1] == \"SAFE\":\n",
    "                thisdir = join(downloaddir, dirlist[y])\n",
    "\n",
    "        # find GRANULE subdirectory\n",
    "        thisdir = join(thisdir, \"GRANULE\")\n",
    "\n",
    "        # find L2A_* subdirectory\n",
    "        dirlist = [d for d in listdir(thisdir) if isdir(join(thisdir, d))]\n",
    "        for y in range(len(dirlist)):\n",
    "            if dirlist[y].split(\"_\")[0] == \"L2A\":\n",
    "                thisdir = join(thisdir, dirlist[y])\n",
    "\n",
    "        # find IMG_DATA subdirectory\n",
    "        thisdir = join(thisdir, \"IMG_DATA\")\n",
    "\n",
    "        # find R10m subdirectory\n",
    "        thisdir = join(thisdir, \"R10m\")\n",
    "\n",
    "        # call our function to convert the granule into a Geotiff file\n",
    "        s2tiff(thisdir,tiffdir, sceneID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All files:\n",
      "['S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956_16Bit.tif', 'S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522_16Bit.tif', 'S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218_16Bit.tif', 'S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218_16Bit.tif', 'S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218_16Bit.tif', 'S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557_16Bit.tif', 'S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557_16Bit.tif', 'S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557_16Bit.tif', 'S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715_16Bit.tif', 'S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135_16Bit.tif']\n",
      "\n",
      "All acquisition dates (sorted):\n",
      "['20190512', '20190514', '20190524', '20190603', '20190628', '20190629']\n",
      "\n",
      "Images taken on date 20190512\n",
      "['S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956_16Bit.tif']\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190512.vrt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190512.png\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956_16Bit.tif\n",
      "True\n",
      "gdalbuildvrt -overwrite -input_file_list /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190512.vrt\n",
      "Created VRT file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190512.vrt\n",
      "gdal_translate -of PNG -ot Byte -scale -outsize 10% 10% /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190512.vrt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190512.png\n",
      "Created quicklook mosaic file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190512.png\n",
      "\n",
      "Images taken on date 20190628\n",
      "['S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522_16Bit.tif']\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190628.vrt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190628.png\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522_16Bit.tif\n",
      "True\n",
      "gdalbuildvrt -overwrite -input_file_list /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190628.vrt\n",
      "Created VRT file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190628.vrt\n",
      "gdal_translate -of PNG -ot Byte -scale -outsize 10% 10% /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190628.vrt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190628.png\n",
      "Created quicklook mosaic file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190628.png\n",
      "\n",
      "Images taken on date 20190514\n",
      "['S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218_16Bit.tif', 'S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218_16Bit.tif', 'S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218_16Bit.tif']\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190514.vrt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190514.png\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218_16Bit.tif\n",
      "True\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218_16Bit.tif\n",
      "True\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218_16Bit.tif\n",
      "True\n",
      "gdalbuildvrt -overwrite -input_file_list /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190514.vrt\n",
      "Created VRT file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190514.vrt\n",
      "gdal_translate -of PNG -ot Byte -scale -outsize 10% 10% /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190514.vrt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190514.png\n",
      "Created quicklook mosaic file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190514.png\n",
      "\n",
      "Images taken on date 20190524\n",
      "['S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557_16Bit.tif', 'S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557_16Bit.tif', 'S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557_16Bit.tif']\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190524.vrt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190524.png\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557_16Bit.tif\n",
      "True\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557_16Bit.tif\n",
      "True\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557_16Bit.tif\n",
      "True\n",
      "gdalbuildvrt -overwrite -input_file_list /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190524.vrt\n",
      "Created VRT file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190524.vrt\n",
      "gdal_translate -of PNG -ot Byte -scale -outsize 10% 10% /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190524.vrt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190524.png\n",
      "Created quicklook mosaic file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190524.png\n",
      "\n",
      "Images taken on date 20190603\n",
      "['S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715_16Bit.tif']\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190603.vrt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190603.png\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715_16Bit.tif\n",
      "True\n",
      "gdalbuildvrt -overwrite -input_file_list /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190603.vrt\n",
      "Created VRT file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190603.vrt\n",
      "gdal_translate -of PNG -ot Byte -scale -outsize 10% 10% /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190603.vrt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190603.png\n",
      "Created quicklook mosaic file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190603.png\n",
      "\n",
      "Images taken on date 20190629\n",
      "['S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135_16Bit.tif']\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190629.vrt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190629.png\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/tiff/S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135_16Bit.tif\n",
      "True\n",
      "gdalbuildvrt -overwrite -input_file_list /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/filelist.txt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190629.vrt\n",
      "Created VRT file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190629.vrt\n",
      "gdal_translate -of PNG -ot Byte -scale -outsize 10% 10% /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190629.vrt /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190629.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created quicklook mosaic file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/quicklooks/S2_20190629.png\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# 4. Save quicklooks of all image mosaics for each image acquisiton date\n",
    "#######################################################################\n",
    "\n",
    "# function to eliminate duplicate entries in a list by converting to a dictionary and back\n",
    "def remove_duplicates(x):\n",
    "    return list(dict.fromkeys(x))\n",
    "\n",
    "# get list of all tiff files in the data directory\n",
    "allfiles = [f for f in listdir(tiffdir) if (isfile(join(tiffdir, f)) and f.endswith('.tif'))]\n",
    "\n",
    "print(\"\\nAll files:\")\n",
    "print(allfiles)\n",
    "\n",
    "# pull out all acquisition dates from the file names\n",
    "# for the Sentinel-2 naming convention, see \n",
    "#     https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/naming-convention\n",
    "acqdates = remove_duplicates([f.split(\"_\")[2].split(\"T\")[0] for f in allfiles])\n",
    "\n",
    "print(\"\\nAll acquisition dates (sorted):\")\n",
    "print([f for f in sorted(acqdates)])\n",
    "\n",
    "# go through all dates\n",
    "for d in acqdates:\n",
    "    \n",
    "    # pull out all file names of the same acquisition date\n",
    "    files2mosaic = [f for f in allfiles if (f.split(\"_\")[2].split(\"T\")[0] == d)]\n",
    "\n",
    "    print(\"\\nImages taken on date \" + d)\n",
    "    print(files2mosaic)\n",
    "    \n",
    "    # define a filename for the output file\n",
    "    mosaicID = \"S2_\" + d\n",
    "\n",
    "    # call our function\n",
    "    quicklooks(tiffdir, files2mosaic, quickdir, mosaicID, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# 5. Extract polygon statistics of NDVI as a time series from all data\n",
    "#######################################################################\n",
    "\n",
    "def tif2raster(tiffile):\n",
    "    # read in a geotiff file (unsigned 16-bit integer format) and turn into a Python raster object\n",
    "    img_ds = io.imread(tiffile)\n",
    "    # convert to 16bit numpy array \n",
    "    img = np.array(img_ds, dtype='int16')\n",
    "    return(img)\n",
    "\n",
    "def zonal_stats(feat, input_zone_polygon, input_tiff, verbose = False):\n",
    "    '''\n",
    "        extracts statistics from a feature (polygon) of a shapefile from a tiff file with several bands\n",
    "        adapted from:\n",
    "        https://gis.stackexchange.com/questions/208441/zonal-statistics-of-a-polygon-and-assigning-mean-value-to-the-polygon\n",
    "    '''\n",
    "\n",
    "    if verbose:\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "        print(\"Processing raster file: \" + input_tiff)\n",
    "        \n",
    "    # Open vector data\n",
    "    shp = ogr.Open(input_zone_polygon)\n",
    "    lyr = shp.GetLayer()\n",
    "\n",
    "    # Get raster georeference info\n",
    "    dataset = gdal.Open(input_tiff, gdal.GA_ReadOnly)\n",
    "    if not dataset:\n",
    "        print(\"Error. Tiff file not found: \" + input_tiff)\n",
    "\n",
    "    ncols = dataset.RasterXSize\n",
    "    nrows = dataset.RasterYSize\n",
    "    nbands = dataset.RasterCount\n",
    "    wkt_projection = dataset.GetProjection()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Raster size: {} x {} x {}\".format(ncols, nrows, nbands))\n",
    "        print(\"Raster projection: {}\".format(wkt_projection))\n",
    "\n",
    "    geotransform = dataset.GetGeoTransform()\n",
    "    if geotransform:\n",
    "        xOrigin = geotransform[0]\n",
    "        yOrigin = geotransform[3]\n",
    "        pixelWidth = geotransform[1]\n",
    "        pixelHeight = geotransform[5]\n",
    "        if verbose:\n",
    "            print(\"Tiff file image origin xmin,yax = ({}, {})\".format(geotransform[0], geotransform[3]))\n",
    "            print(\"Pixel Size x,y = ({}, {})\".format(geotransform[1], geotransform[5]))\n",
    "    else:\n",
    "        print(\"Error. Geotransform not found in tiff file: \" + input_tiff) \n",
    "\n",
    "    # Reproject vector geometry to same projection as raster\n",
    "    sourceSR = lyr.GetSpatialRef()\n",
    "    targetSR = osr.SpatialReference()\n",
    "    targetSR.ImportFromWkt(wkt_projection)\n",
    "    coordTrans = osr.CoordinateTransformation(sourceSR,targetSR)\n",
    "    feat = lyr.GetNextFeature()\n",
    "    geom = feat.GetGeometryRef()\n",
    "    geom.Transform(coordTrans)\n",
    "\n",
    "    # Get extent of the feature for which to extract the raster statistics\n",
    "    geom = feat.GetGeometryRef()\n",
    "    if (geom.GetGeometryName() == 'MULTIPOLYGON'):\n",
    "        count = 0\n",
    "        pointsX = []; pointsY = []\n",
    "        for polygon in geom:\n",
    "            geomInner = geom.GetGeometryRef(count)\n",
    "            ring = geomInner.GetGeometryRef(0)\n",
    "            numpoints = ring.GetPointCount()\n",
    "            for p in range(numpoints):\n",
    "                    lon, lat, z = ring.GetPoint(p)\n",
    "                    pointsX.append(lon)\n",
    "                    pointsY.append(lat)\n",
    "            count += 1\n",
    "    elif (geom.GetGeometryName() == 'POLYGON'):\n",
    "        ring = geom.GetGeometryRef(0)\n",
    "        numpoints = ring.GetPointCount()\n",
    "        pointsX = []; pointsY = []\n",
    "        for p in range(numpoints):\n",
    "                lon, lat, z = ring.GetPoint(p)\n",
    "                pointsX.append(lon)\n",
    "                pointsY.append(lat)\n",
    "\n",
    "    else:\n",
    "        sys.exit(\"ERROR: Geometry needs to be either Polygon or Multipolygon\")\n",
    "\n",
    "    # extent of this feature in map coordinates\n",
    "    xmin = min(pointsX)\n",
    "    xmax = max(pointsX)\n",
    "    ymin = min(pointsY)\n",
    "    ymax = max(pointsY)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nFeature extent in map coordinates: xmin,xmax, ymin, ymax\", xmin, xmax, ymin, ymax)\n",
    "       \n",
    "    # raster layer extent in map coordinates\n",
    "    xmin1 = xOrigin\n",
    "    xmax1 = xOrigin + ncols * pixelWidth\n",
    "    ymin1 = yOrigin + nrows * pixelHeight\n",
    "    ymax1 = yOrigin\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nGeotiff raster extent in map coordinates: xmin1, xmax1, ymin1, ymax1\")\n",
    "        print(xmin1,xmax1,ymin1,ymax1)\n",
    "    \n",
    "    # extent of the intersect between the featurs / polygon / zone and the raster image in map coordinates\n",
    "    xmin2 = max(xmin,xmin1)\n",
    "    xmax2 = min(xmax,xmax1)\n",
    "    ymin2 = max(ymin,ymin1)\n",
    "    ymax2 = min(ymax,ymax1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nIntersect extent in map coordinates: xmin2, xmax2, ymin2, ymax2\")\n",
    "        print(xmin2,xmax2,ymin2,ymax2)\n",
    "    \n",
    "    # clip the Geotiff raster layer to the extent of the intersect with the feature\n",
    "    xoff = int((xmin2 - xOrigin)/pixelWidth)\n",
    "    yoff = int((yOrigin - ymax2)/pixelWidth)\n",
    "    xcount = int((xmax2 - xmin2)/pixelWidth)\n",
    "    ycount = int((ymax2 - ymin2)/pixelWidth)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nclipped raster layer extent in pixels: xoff, yoff, xcount, ycount\")\n",
    "        print(\"xoff = \", xoff)\n",
    "        print(\"yoff = \", yoff)\n",
    "        print(\"xcount = \", xcount)\n",
    "        print(\"ycount = \", ycount)\n",
    "\n",
    "    # clip the rasterised feature layer to the extent of the intersect with the feature\n",
    "    xoff1 = int((xmin2 - xmin)/pixelWidth)\n",
    "    yoff1 = int((ymax - ymax2)/pixelWidth)\n",
    "    xcount1 = int((xmax2 - xmin2)/pixelWidth)\n",
    "    ycount1 = int((ymax2 - ymin2)/pixelWidth)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nclipped feature layer extent in pixels: xoff1,yoff1,xcount1,ycount1\")\n",
    "        print(\"xoff1 = \", xoff1)\n",
    "        print(\"yoff1 = \", yoff1)\n",
    "        print(\"xcount1 = \", xcount1)\n",
    "        print(\"ycount1 = \", ycount1)\n",
    "    \n",
    "    # Create memory target raster for the mask with all pixels within the feature (zone)\n",
    "    target_ds = gdal.GetDriverByName('MEM').Create('', xcount, ycount, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((xmin2, pixelWidth, 0, ymax2, 0, pixelHeight,))\n",
    "\n",
    "    # make projection the same as for the Geotiff Sentinel-2 raster file\n",
    "    target_ds.SetProjection(wkt_projection)\n",
    "\n",
    "    # create an empty array to hold the statistics results for all bands\n",
    "    stats = np.zeros((nbands, 7))\n",
    "\n",
    "    # loop over all bands\n",
    "    for band in range(1, nbands + 1):\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nBand \", band)\n",
    "        \n",
    "        # Rasterize the feature (zone polygon) to the target raster layer\n",
    "        #   burn_value of 1 indicates that a pixels is within the feature (zone)\n",
    "        gdal.RasterizeLayer(target_ds, [1], lyr, burn_values=[1]) #, ['ALL_TOUCHED=TRUE']\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Zone mask raster size: \", target_ds.GetRasterBand(1).ReadAsArray().shape)\n",
    "            print(\"Zone mask raster min,max: \", np.nanmin(target_ds.GetRasterBand(1).ReadAsArray()), np.nanmax(target_ds.GetRasterBand(1).ReadAsArray()))\n",
    "            # Display the whole rasterised zone mask\n",
    "            plt.figure().suptitle(\"Zone mask\")\n",
    "            io.imshow(np.array(target_ds.GetRasterBand(1).ReadAsArray()), cmap='gray_r')\n",
    "            # Display the whole Sentinel-2 image band\n",
    "            plt.figure().suptitle(\"Image band \"+str(band))\n",
    "            p2, p98 = np.percentile(np.array(dataset.GetRasterBand(1).ReadAsArray()), (2, 98))\n",
    "            img = exposure.rescale_intensity(np.array(dataset.GetRasterBand(1).ReadAsArray()), in_range=(p2, p98)) # Contrast stretching\n",
    "            io.imshow(img, cmap='gray_r')\n",
    "\n",
    "        # Read intersecting Geotiff raster layer values as an array\n",
    "        dataraster = np.array(dataset.GetRasterBand(band).ReadAsArray(xoff, yoff, xcount, ycount)).astype(np.float)\n",
    "\n",
    "        # clip the rasterised feature layer to the extent of the intersect with the geotiff raster layer\n",
    "        datamask = target_ds.GetRasterBand(1).ReadAsArray().astype(np.byte)\n",
    "\n",
    "        # do something here to catch situations where dataraster is all NaNs\n",
    "        #    replace 1 in datamask with 0 where NaNs are found in dataraster\n",
    "        datamask[np.isnan(dataraster)] = 0\n",
    "\n",
    "        warnme = 0 # no warnings so far\n",
    "\n",
    "        if (np.nanmin(dataraster) == np.nan and np.nanmax(dataraster) == np.nan):\n",
    "            print(\"WARNING: All dataraster values are NaN.\")\n",
    "            warnme = warnme + 1\n",
    "        else:\n",
    "            if (dataraster.shape == ()):\n",
    "                print(\"WARNING: Failed to create dataraster.\")\n",
    "                warnme = warnme + 1\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"Data raster min, max: \", np.nanmin(dataraster), np.nanmax(dataraster))\n",
    "                    # contrast stretching\n",
    "                    p2, p98 = np.percentile(dataraster, (2, 98))\n",
    "                    img = exposure.rescale_intensity(dataraster, in_range=(p2, p98)) # Contrast stretching\n",
    "                    plt.figure().suptitle(\"Data raster\")\n",
    "                    io.imshow(img, cmap='gray_r')\n",
    "\n",
    "                if (np.min(datamask) == 0 and np.max(datamask) == 0):\n",
    "                    print(\"WARNING: All datamask values are zero.\")\n",
    "                    warnme = warnme + 1\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(\"Data mask min, max: \", np.min(datamask), np.max(datamask))\n",
    "                        plt.figure().suptitle(\"Data mask\")\n",
    "                        io.imshow(datamask, cmap='gray_r')\n",
    "\n",
    "                    # Apply the mask from the rasterised feature layer (zone polygon) to the Geotiff raster\n",
    "                    zoneraster = np.ma.MaskedArray(dataraster, datamask)\n",
    "\n",
    "                    if (np.min(zoneraster) == 0 and np.max(zoneraster) == 0):\n",
    "                        print(\"WARNING: All zoneraster values are zero.\")\n",
    "                        warnme = warnme + 1\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(\"Zone raster min, max: \", np.min(zoneraster.data), np.max(zoneraster.data))\n",
    "                            p2, p98 = np.percentile(zoneraster, (2, 98))\n",
    "                            img = exposure.rescale_intensity(zoneraster, in_range=(p2, p98)) # Contrast stretching\n",
    "                            plt.figure().suptitle(\"Zone raster\")\n",
    "                            io.imshow(img, cmap='gray_r')\n",
    "\n",
    "        if verbose:\n",
    "            io.show()\n",
    "\n",
    "        # calculate band statistics under the zone mask\n",
    "        # N.B. The -1 is there to get Python indices from 0...3 from the band variable 1...4 (see for loop)\n",
    "        stats[band - 1, 0] = band\n",
    "        stats[band - 1, 1] = np.ma.average(zoneraster)\n",
    "        stats[band - 1, 2] = np.ma.mean(zoneraster)\n",
    "        stats[band - 1, 3] = np.ma.median(zoneraster)\n",
    "        stats[band - 1, 4] = np.ma.std(zoneraster)\n",
    "        stats[band - 1, 5] = np.ma.var(zoneraster)\n",
    "        stats[band - 1, 6] = np.ma.sum(zoneraster)       \n",
    "        \n",
    "    # close files\n",
    "    dataset = None\n",
    "    shp = None\n",
    "    \n",
    "    # free up memory\n",
    "    target_ds = None\n",
    "\n",
    "    if (warnme > 0):\n",
    "        print(warnme, \" WARNINGS issued. Returning zero values from the zone statistics function.\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def loop_zonal_stats(input_zone_polygon, input_tiff, verbose = False):\n",
    "\n",
    "    shp = ogr.Open(input_zone_polygon)\n",
    "    lyr = shp.GetLayer()\n",
    "    featList = range(lyr.GetFeatureCount())\n",
    "    statDict = {}\n",
    "\n",
    "    for FID in featList:\n",
    "        if verbose:\n",
    "            print(\"Feature ID: \", FID)\n",
    "        feat = lyr.GetFeature(FID)\n",
    "        meanValue = zonal_stats(feat, input_zone_polygon, input_tiff, verbose)\n",
    "        statDict[FID] = meanValue\n",
    "    return statDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All tile IDs covered (sorted):\n",
      "T30UXD\n",
      "T30UYD\n",
      "T30UYE\n",
      "T31UCU\n",
      "\n",
      "\n",
      "\n",
      "Image files covering tile T30UXD\n",
      "S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522_16Bit.tif\n",
      "S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218_16Bit.tif\n",
      "S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135_16Bit.tif\n",
      "\n",
      "Acquisition dates for this tile (sorted):\n",
      "['20190514', '20190628', '20190629']\n",
      "\n",
      "Saving tile statistics to file:  /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/outputs/S2_T30UXD.txt\n",
      "processing file S2A_MSIL2A_20190628T105621_N0212_R094_T30UXD_20190628T141522_16Bit.tif\n",
      "acqdate 20190628\n",
      "processing file S2B_MSIL2A_20190514T105629_N0212_R094_T30UXD_20190514T125218_16Bit.tif\n",
      "acqdate 20190514\n",
      "processing file S2B_MSIL2A_20190629T112119_N0212_R037_T30UXD_20190629T132135_16Bit.tif\n",
      "acqdate 20190629\n",
      "\n",
      "Image files covering tile T30UYD\n",
      "S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218_16Bit.tif\n",
      "S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557_16Bit.tif\n",
      "\n",
      "Acquisition dates for this tile (sorted):\n",
      "['20190514', '20190524']\n",
      "\n",
      "Saving tile statistics to file:  /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/outputs/S2_T30UYD.txt\n",
      "processing file S2B_MSIL2A_20190514T105629_N0212_R094_T30UYD_20190514T125218_16Bit.tif\n",
      "acqdate 20190514\n",
      "processing file S2B_MSIL2A_20190524T105629_N0212_R094_T30UYD_20190524T135557_16Bit.tif\n",
      "acqdate 20190524\n",
      "\n",
      "Image files covering tile T30UYE\n",
      "S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956_16Bit.tif\n",
      "S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557_16Bit.tif\n",
      "S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715_16Bit.tif\n",
      "\n",
      "Acquisition dates for this tile (sorted):\n",
      "['20190512', '20190524', '20190603']\n",
      "\n",
      "Saving tile statistics to file:  /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/outputs/S2_T30UYE.txt\n",
      "processing file S2A_MSIL2A_20190512T110621_N0212_R137_T30UYE_20190512T122956_16Bit.tif\n",
      "acqdate 20190512\n",
      "processing file S2B_MSIL2A_20190524T105629_N0212_R094_T30UYE_20190524T135557_16Bit.tif\n",
      "acqdate 20190524\n",
      "processing file S2B_MSIL2A_20190603T105629_N0212_R094_T30UYE_20190603T140715_16Bit.tif\n",
      "acqdate 20190603\n",
      "\n",
      "Image files covering tile T31UCU\n",
      "S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218_16Bit.tif\n",
      "S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557_16Bit.tif\n",
      "\n",
      "Acquisition dates for this tile (sorted):\n",
      "['20190514', '20190524']\n",
      "\n",
      "Saving tile statistics to file:  /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/outputs/S2_T31UCU.txt\n",
      "processing file S2B_MSIL2A_20190514T105629_N0212_R094_T31UCU_20190514T125218_16Bit.tif\n",
      "acqdate 20190514\n",
      "processing file S2B_MSIL2A_20190524T105629_N0212_R094_T31UCU_20190524T135557_16Bit.tif\n",
      "acqdate 20190524\n"
     ]
    }
   ],
   "source": [
    "# pull out all tile IDs from the file names\n",
    "# the tiling grid can be downloaded from here as a .kml file:\n",
    "#     https://sentinel.esa.int/web/sentinel/missions/sentinel-2/data-products\n",
    "tiles = sorted(remove_duplicates([f.split(\"_\")[5] for f in allfiles]))\n",
    "\n",
    "print(\"\\nAll tile IDs (sorted):\")\n",
    "for t in tiles:\n",
    "    print(t)\n",
    "print(\"\\n\") # new line\n",
    "\n",
    "# check whether shapefile exists\n",
    "if not os.path.exists(shapefile):\n",
    "    print('Shapefile not found: ' + shapefile)\n",
    "else:\n",
    "    # go through all tiles and extract statistics for all available acquisition dates for that tile\n",
    "    \n",
    "    for t in tiles:\n",
    "\n",
    "        # get all file names with the same tile ID from the list of all tiff files\n",
    "        filestack = [f for f in allfiles if (f.split(\"_\")[5] == t)]\n",
    "        print(\"\\nImage files acquired for tile \" + t)\n",
    "        for xfile in filestack:\n",
    "            print(xfile)\n",
    "\n",
    "        # pull out all acquisition dates from the file names\n",
    "        acqdates = remove_duplicates([f.split(\"_\")[2].split(\"T\")[0] for f in filestack])\n",
    "        print(\"\\nAcquisition dates for this tile (sorted):\")\n",
    "        print([f for f in sorted(acqdates)])\n",
    "        \n",
    "        # define a filename for the output text file with the statistics\n",
    "        timeseries = join(outdir, \"S2_\" + t + \".txt\")\n",
    "        print(\"\\nSaving tile statistics to file: \", timeseries)\n",
    "        outfile = open(timeseries, \"w\")\n",
    "\n",
    "        # write header line\n",
    "        outfile.write(\"AcqDate, Zone, Band, Average, Mean, Median, Std_Deviation, Variance, N_Pixels\\n\")\n",
    "\n",
    "        # for each acquisition date, get the polygon statistics of that tile\n",
    "        for xfile in filestack:\n",
    "\n",
    "            # get acquisition date for that file\n",
    "            acqdate = xfile.split(\"_\")[2].split(\"T\")[0]\n",
    "\n",
    "            # run the loop over all polygons (zones) and all image files\n",
    "            result_dict = loop_zonal_stats(shapefile, join(tiffdir, xfile), verbose = False)\n",
    "\n",
    "            # save acquisition dates and statistics of that tile to the statistics file\n",
    "            # for each zone (polygon ID) in the results dictionary, there is an array with the statistics for each band\n",
    "            for zone, stat in result_dict.items():\n",
    "                for band in range(stat.shape[0]):\n",
    "                    outfile.write(acqdate + ', ' + str(zone) + ', ')\n",
    "                    this_line = list(stat[band, ]) # line of statistics for output file\n",
    "                    for item in this_line:\n",
    "                        if item == this_line[0]: # first item in the line\n",
    "                            outfile.write(\"%s, \" % np.int32(item))\n",
    "                        else:\n",
    "                            if item == this_line[len(this_line) - 1]:  # last item in the line\n",
    "                                outfile.write(\"%s\\n\" % item)\n",
    "                            else:\n",
    "                                outfile.write(\"%s, \" % item) # all other items in the line\n",
    "\n",
    "        outfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
