{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"practical_sync_week7_SentinelSat.ipynb","provenance":[{"file_id":"15AIJzS_uoHPaoO0tuefzEUCI2YC8oMEk","timestamp":1605709335724}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"XUexW0CmhlF3"},"source":["# Week 7: Accessing the Copernicus Open Access Hub with the SentinelSat library\n","\n","Individual learning outcomes: At the end of this week, all students should be able to access the Copernicus Open Access Hub via the API, set up and submit a data query and automatically download individual Sentinel-2 images to Google Drive and Colab for further analysis. Students should understand the Sentinel-2 file structure and to pre-process the image automatically, including unzipping, reprojecting, and clipping.\n","\n","The Copernicus Open Access Hub allows you to do a search for single images. However, there are limitations as to how many and which images you can request from the Long-Term Archive.\n","\n","https://sentinel.esa.int/web/sentinel/-/activation-of-long-term-archive-lta-access-for-copernicus-sentinel-2-and-3\n"]},{"cell_type":"markdown","metadata":{"id":"1skim1-_4qGc"},"source":["# Get a user account on the Sentinel Open Access Data Hub\n","\n","Before we begin, make sure to register for an account in the Copernicus Open Access Hub.\n","\n","For registration follow the link to the Open Access Hub and register: https://scihub.copernicus.eu/dhus/#/home\n","\n","In previous weeks, we had manually uploaded a Sentinel-2 image to our Google Drive directory. We had also used Google Earth Engine to process multi-temporal Sentinel-2 images into image composites for us.\n","\n","Today, we want to access the Sentinel Data Hub and search for available images over an area of interest of our choice."]},{"cell_type":"markdown","metadata":{"id":"___N_2vyp_f2"},"source":["Connect to our Google Drive from Colab."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"RvpK17wXp_f7"},"source":["# Load the Drive helper and mount your Google Drive as a drive in the virtual machine\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fajjFxKt5nwT"},"source":["## Sentinelsat API\n","\n","We'll be using an API designed by Wille and Clauss (2016) called sentinelsat. This API was designed to query and download Copernicus product imagery from the Copernicus Open Access Hub API.\n","\n","Follow the link to the API, and see if you can understand how it works: https://sentinelsat.readthedocs.io/en/stable/"]},{"cell_type":"code","metadata":{"id":"HXnzg_pcTSEP"},"source":["#import required libraries, including the sentinelsat library this time\n","!pip install rasterio\n","!pip install sentinelsat\n","!pip install geopandas\n","!pip install rasterstats\n","\n","import geopandas as gpd\n","import rasterio\n","from rasterio import plot\n","from rasterio.plot import show_hist\n","from rasterio.windows import Window\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt, geojson\n","from collections import OrderedDict\n","import json\n","import math\n","from osgeo import ogr\n","import os\n","from os import listdir\n","from os.path import isfile, isdir, join\n","from pyproj import Proj\n","from pprint import pprint\n","import shutil\n","import sys\n","import zipfile\n","from math import floor, ceil\n","\n","# make sure that this path points to the location of the pygge module on your Google Drive\n","libdir = '/content/drive/MyDrive/practicals21-22' # this is where pygge.py needs to be saved\n","if libdir not in sys.path:\n","    sys.path.append(libdir)\n","\n","# import the pygge module\n","import pygge\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fcro81WxTf4_"},"source":["# Accessing Sentinel-2 images\n","\n","The workflow for this practical is similar to the previous one:\n","* Define an area of interest based on an ESRI shapefile\n","* Define a time window for our data search\n","* Set a maximum acceptable cloud cover for our search\n","* Search the ESA Copernicus Open Access Hub for all available images\n","* Select the individual images with the least cloud cover and download them to Google Drive\n","* Reproject (warp) the TCI images and crop them to our area of interest"]},{"cell_type":"markdown","metadata":{"id":"7MWM3wcwTf5P"},"source":["Before proceeding, we have to go to Google Drive and create a text file called \"sencredentials.txt\" with your personal login details for the ESA Copernicus Sentinel Hub. Do not share your login details with anyone.\n","\n","The file has two lines of text.\n","\n","Line 1: Your username\n","\n","Line 2: Your password"]},{"cell_type":"markdown","metadata":{"id":"kmx17s7RvTG9"},"source":["#Set the directory paths on Google Drive."]},{"cell_type":"code","metadata":{"id":"wzmlF4GQD1ji"},"source":["# BEFORE YOU RUN THIS BLOCK, YOU NEED A USER ACCOUNT ON THE ESA SENTINEL HUB\n","# In a browser, go to https://scihub.copernicus.eu/dhus/#/home\n","# Click on the user symbol in the top right and then on 'sign up'\n","# Follow the instructions.\n","# When you have your account, create a .txt file in Word that contains two lines:\n","#   line 1 - your username\n","#   line 2 - your password\n","# save it under the name \"sencredentials.txt\"\n","# upload it to the same directory as the Jupyter Notebook on your Google Drive.\n","\n","# path to your Google Drive\n","# EDIT THIS LINE (/content/drive/My Drive is the top directory on Google Drive):\n","wd = \"/content/drive/MyDrive/practicals21-22\"\n","print(\"Connected to data directory: \" + wd)\n","print(\"\\nList of contents of \" + wd)\n","for f in sorted(os.listdir(wd)):\n","  print(f)\n","\n","# path to your temporary drive on the Colab Virtual Machine\n","cd = \"/content/work\"\n","print(\"Temporary work directory: \", cd)\n","\n","# This file will allow the notebook to connect to your account on the ESA Data Archive.\n","credentials = join(wd, 'sencredentials.txt')  # contains two lines of text with username and password\n","\n","# directory for downloading the Sentinel-2 granules\n","downloaddir = join(cd, 'download') # where we save the downloaded images\n","quickdir = join(cd, 'quicklooks')  # where we save the quicklooks\n","outdir = join(cd, 'out')           # where we save any other outputs\n","\n","# CAREFUL: This code removes the named directories and everything inside them to free up space\n","# Note: shutil provides a lot of useful functions for file and directory management\n","try:\n","  shutil.rmtree(downloaddir)\n","except:\n","  print(downloaddir + \" not found.\")\n","\n","try:\n","  shutil.rmtree(quickdir)\n","except:\n","  print(quickdir + \" not found.\")\n","\n","try:\n","  shutil.rmtree(outdir)\n","except:\n","  print(outdir + \" not found.\")\n","\n","# create the new directories, unless they already exist\n","os.makedirs(cd, exist_ok=True)\n","os.makedirs(downloaddir, exist_ok=True)\n","os.makedirs(quickdir, exist_ok=True)\n","os.makedirs(outdir, exist_ok=True)\n","\n","# check whether the file with the login details exists\n","if \"sencredentials.txt\" not in os.listdir(wd):\n","  print(\"\\nERROR: File sencredentials.txt not found. Cannot log in to Data Hub.\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H0-BMbjnTf5K"},"source":["Set up some directory names. \n","\n","Modify these string variables to match your data directory structure.\n","\n","IMPORTANT: You must upload a shapefile of your area of interest to your Google Drive before running the next cell. Set the variable 'shapefile' below to point to this file. You can draw a polygon and save it as a shapefile on http://www.geojson.io."]},{"cell_type":"code","metadata":{"id":"jy8PKeYGTf5Q"},"source":["# EDIT THE SEARCH AND DOWNLOAD OPTIONS BELOW\n","ndown = 3 # number of scenes to be downloaded (in order of least cloud cover)\n","shapefile = join(wd, 'oakham', 'Polygons_small.shp') # ESRI Shapefile of the study area\n","\n","# Define a date range for our search\n","# WARNING: You need to check whether your images are available for download or\n","#          have been moved to the Long-Term Archive: \n","#          https://scihub.copernicus.eu/userguide/LongTermArchive\n","datefrom = '20210401' # start date for imagery search\n","dateto   = '20210930' # end date for imagery search\n","\n","# Define which cloud cover we accept in the images\n","clouds = '[0 TO 10]' # range of acceptable cloud cover % for imagery search"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ss25DF_R3CXo"},"source":["# Search for available image files on the ESA data server\n","\n","We begin by reading in the user name and password we have saved in our text file 'sencredentials.txt'."]},{"cell_type":"code","metadata":{"id":"wV1byFoZKbtq"},"source":["# go to working directory\n","os.chdir(wd)\n","\n","# load user credentials for Sentinel Data Hub at ESA, i.e. read two lines of text with username and password\n","with open(join(wd, credentials)) as f:\n","    lines = f.readlines()\n","username = lines[0].strip()\n","password = lines[1].strip()\n","f.close()\n","\n","# do the search\n","api, products = pygge.search_Cop_Hub(api='https://scihub.copernicus.eu/dhus', \n","                                     username=username, password=password,\n","                                     shapefile=shapefile, datefrom=datefrom, \n","                                     dateto=dateto, platformname='Sentinel-2', \n","                                     processinglevel='Level-2A', clouds=clouds)\n","\n","# convert the ordered dictionary to a dataframe\n","products_df = api.to_dataframe(products)\n","print(products_df.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-5IAPzszK674"},"source":["Let's look at the query results, save them in a format that can be read into Excel and select the images we want to download."]},{"cell_type":"code","metadata":{"id":"Sghwq092Kbtt"},"source":["print('Search resulted in '+str(products_df.shape[0])+' satellite images with '+\n","      str(products_df.shape[1])+' attributes.')\n","\n","os.chdir(outdir) # set working direcory for output files\n","\n","# sort the search results\n","products_df_sorted = products_df.sort_values(['cloudcoverpercentage', 'ingestiondate'], ascending=[True, True])\n","print(\"Sorted search results:\")\n","print(products_df_sorted)\n","\n","# save the full search results to a .csv file that you can read into Excel\n","outfile = 'searchresults_full.csv'\n","products_df_sorted.to_csv(outfile)\n","print(\"Search results saved: \" + outfile)\n","\n","# limit the download to the first 'ndown' images \n","#   sorted by lowest cloud cover and earliest acquisition date\n","products_df_n = products_df_sorted.head(ndown)\n","print(\"Download list of selected images:\")\n","print(products_df_n)\n","\n","# save the list of data to be downloaded to a .csv file that you can read into Excel\n","outfile = 'searchresults4download.csv'\n","products_df_n.to_csv(outfile)\n","print(\"Download list saved: \" + outfile)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2DYvzmz_uIR"},"source":["# Download the individual Sentinel-2 granules to Google Drive\n","This takes a long time if many images are selected. Each is 100x100 km in size and has bands of 10 m and coarser resolution.\n"]},{"cell_type":"code","metadata":{"id":"ZSGlMtjLKbtt"},"source":["# Download all selected images into a data directory\n","os.chdir(downloaddir) # set working direcory to download directory\n","\n","# print the unique image IDs and download the images from the API\n","for i in products_df_n['uuid']:\n","  # check which images are in the Long-Term Archive\n","  is_online = api.is_online(i)\n","  if is_online:\n","    print('Product ',i , ' is online. Starting download.')\n","    api.download(i)\n","  else:\n","    print('Product ',i , ' is not online and would have to be retrieved from the Long-Term Archive.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xbeTnWOEK-da"},"source":["We can save the footprints of the images returned in the query as a Geojson file. To do this, first we extract the selection of images for download from the complete ordered dictionary with our search results of Sentinel-2 products. Then, we put the selected data products into a new ordered dictionary with our selection of images for which we want to get the footprints. After that, we can plot the footprints of the images. "]},{"cell_type":"code","metadata":{"id":"D7DmNDkOKbtt"},"source":["# get the footprints of the selected scenes for use in Excel\n","s2footprints = products_df_n.footprint\n","# save them as an Excel file\n","outfile = join(outdir, 'footprints.csv')\n","s2footprints.to_csv(outfile, header = False)\n","print(\"Granule footprints saved as csv: \" + outfile)\n","\n","# define a function that filters an ordered dictionary by several keys\n","# from https://www.codegrepper.com/code-examples/python/python+select+multiple+keys+from+dict\n","dict_filter = lambda x, y: dict([ (i,x[i]) for i in x if i in set(y) ])\n","\n","# define the keys (unique image IDs) of the downloaded products\n","keys = [uuid for uuid in products_df_n['uuid']]\n","\n","# filter the ordered dictionary with all our product metadata and save those items \n","#   that match the keys in a new ordered dictionary called 'selection'\n","selection = dict_filter(products, keys)\n","\n","# print the keys\n","pprint(keys)\n","\n","# print the selected metadata\n","pprint(selection)\n","\n","# save the footprints of the scenes marked for download together with their metadata in a Geojson file\n","outfile = join(outdir, 'footprints.geojson')\n","with open(outfile, 'w') as f:\n","  json.dump(api.to_geojson(selection), f)\n","print(\"Granule footprints saved as GeoJson: \" + outfile)\n","\n","# plot the footprints and some background layers\n","world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n","\n","# these are the columns in the world geodataframe\n","print(\"Columns in world geodataframe:\")\n","print([i for i in world.columns])\n","# zoom into the country\n","uk = world.loc[world.name == \"United Kingdom\"]\n","print(uk)\n","f = open(outfile)\n","foot = gpd.read_file(f)\n","base = uk.plot(color='white', edgecolor='black')\n","foot.plot(ax=base)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mlB0QLm__yXX"},"source":["# Explore the data directory structure of our downloaded files\n"]},{"cell_type":"code","metadata":{"id":"lZ0b3ZURLOdm"},"source":["# where we stored the text files and csv files\n","os.chdir(outdir)\n","print(\"contents of \", outdir, \":\")\n","!ls -l\n","\n","# where we stored the downloaded Sentinel-2 images\n","os.chdir(downloaddir)\n","print(\"contents of \", downloaddir, \":\")\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrSJL471MrcD"},"source":["Remember that we have saved the downloaded images to a temporary directory that will be deleted when we close the virtual machine. If you want to save your images to your local directory, this is how it goes.\n","\n","Go to your Google Colab  folder in the panel on the left hand side.\n","\n","Find the download directory and click on a Sentinel-2 image folder.\n","\n","Right-click on it and select 'download' to save it."]},{"cell_type":"markdown","metadata":{"id":"cJp7NfpL_1bf"},"source":["# Iterate over all downloaded images and show the TCI file\n"]},{"cell_type":"markdown","metadata":{"id":"CXb24b6hLDui"},"source":["The downloaded Sentinel-2 granules (or single images) are zipped. We need to unzip them first. At this stage, we remove the zipped file to free up disk space."]},{"cell_type":"code","metadata":{"id":"iCwuRpEJLS4E"},"source":["# set working direcory to download directory\n","os.chdir(downloaddir)\n","\n","# get list of all zip files in the data directory\n","allfiles = [f for f in listdir(downloaddir) if isfile(join(downloaddir, f))]\n","\n","# unzip all downloaded Sentinel-2 files\n","for x in range(len(allfiles)):\n","\n","  # we can split the file name and check whether it ends with '.zip'\n","  if allfiles[x].split(\".\")[1] == \"zip\":\n","    print(\"Unzipping file \", x+1, \": \", allfiles[x])\n","\n","    with zipfile.ZipFile(allfiles[x], \"r\") as zipf:\n","      # first extract the files\n","      zipf.extractall(downloaddir)\n","\n","      # then remove the zip file to save disk space\n","      os.remove(join(downloaddir, allfiles[x]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EuDbMvzGUR74"},"source":["Before we can create a quick visualisation of the TCI files of all downloaded images, we need to find all the files. They are located in the 20m subdirectories of our downloaded Sentinel-2 directories for each image.\n","How can we do that? We can iterate over all directories and search for the right files."]},{"cell_type":"code","metadata":{"id":"0Fm_Av5gPOCh"},"source":["tcifiles = pygge.get_filenames(downloaddir, filepattern=\"TCI\", dirpattern=\"R20m\")\n","\n","print(\"\\nList of all TCI files:\")\n","pprint(tcifiles)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QxhvZZe2UmCu"},"source":["Now we know which image files we want to show on screen, the rest is easy. Just like last week."]},{"cell_type":"code","metadata":{"id":"gaCimAhcUlFz"},"source":["# how many files are in the file list?\n","nfiles = len(tcifiles)\n","\n","# arrange our subplots\n","cols = min(nfiles, 4) # maximum of 4 plots in one row\n","rows = math.ceil(nfiles / cols) # round up to nearest integer\n","\n","# create a figure with subplots\n","fig, ax = plt.subplots(rows, cols, figsize=(21,7))\n","fig.patch.set_facecolor('white')\n","\n","# iterate over all Sentinel-2 image directories and show the TCI file to check the image quality on screen\n","for x in range(nfiles):\n","\n","  # join the directory path with the file name\n","  tcifile = tcifiles[x]\n","  print(tcifile)\n","\n","  #open bands as separate single-band raster from the image directory pointing to the 20 m resolution bands\n","  bandTCI = rasterio.open(tcifile, driver='JP2OpenJPEG') #True Colour Image in uint8 data format\n","\n","  #plot band using RasterIO\n","  if nfiles == 1:\n","    plot.show(bandTCI, ax=ax)\n","  else:\n","    plot.show(bandTCI, ax=ax[x])\n","\n","  # set a title for the subplot\n","  if nfiles == 1:\n","    ax.set_title(tcifile.split(\"/\")[-1], fontsize=8)\n","  else:\n","    ax[x].set_title(tcifile.split(\"/\")[-1], fontsize=8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bIpqcW9a8Fnu"},"source":["To zoom to our shapefile area, let's warp all TCI images to the same projection as the shapefile. \n","\n","Remember we did this before with the Google Earth Engine Sentinel-2 image composites."]},{"cell_type":"code","metadata":{"id":"SziStT4I8L0p"},"source":["# get extent, coordinate referencing system and EPSG code of the map projection from the shapefile\n","extent, crs, epsg = pygge.get_shp_extent(shapefile)\n","\n","print(\"Reprojecting all TCI images to projection with EPSG = \", epsg)\n","\n","warpfiles = [] # make an empty list where we can remember all the warped output file names\n","\n","# iterate over all Sentinel-2 image directories and warp the image\n","for tcifile in tcifiles:\n","\n","  # make a directory path and file name for the warped output file\n","  warpfile = join(quickdir, tcifile.split(\"/\")[-1].split(\".\")[0] + \"_warped.jp2\")\n","  warpfiles.append(warpfile) # add it to our list\n","\n","  # call the easy_warp function\n","  tmp = pygge.easy_warp(tcifile, warpfile, epsg)\n","\n","# print the list of new files we have created\n","print(\"List of warped files:\")\n","pprint(warpfiles)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8fRSAityEE5L"},"source":["# Plot the shapefile on top of the warped TCI files\n","\n","We will use the Geopandas library for plotting the shapefile on top of the raster image.\n"]},{"cell_type":"code","metadata":{"id":"Zm_DVizqkATe"},"source":["# open the shapefile for plotting\n","driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n","ds = driver.Open(shapefile, 0)\n","\n","# create a figure with subplots\n","fig, ax = plt.subplots(rows, cols, figsize=(21,7))\n","fig.patch.set_facecolor('white')\n","\n","# read the shapefile\n","shp = gpd.read_file(shapefile)\n","\n","# if only one file is there, then do not loop over all files\n","if len(warpfiles) == 1:\n","  pygge.easy_plot(warpfile, ax, bands=[1,2,3])\n","  # plot the shapefile using Geopandas\n","  shp.boundary.plot(ax=ax, edgecolor=\"yellow\")\n","  # set a title for the subplot\n","  ax.set_title(warpfile.split(\"/\")[-1].split(\".\")[0], fontsize=8)\n","else:\n","  # iterate over all Sentinel-2 image directories and show the TCI file to check the image quality on screen\n","  for i, warpfile in enumerate(warpfiles):\n","    pygge.easy_plot(warpfile, ax[i], bands=[1,2,3])\n","    shp.boundary.plot(ax=ax[i], edgecolor=\"yellow\")\n","    ax[i].set_title(warpfile.split(\"/\")[-1].split(\".\")[0], fontsize=8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1pLK_X_Cjnu7"},"source":["#Clip the raster\n","\n","Let's zoom into our shapefile area and clip the raster files to that area. \n"]},{"cell_type":"code","metadata":{"id":"3Or538qfZoLb"},"source":["# make an empty list where we will remember all clipped file names\n","clipfiles = [] \n","\n","# create a figure with subplots\n","fig, ax = plt.subplots(rows, cols, figsize=(21,7))\n","fig.patch.set_facecolor('white')\n","\n","# iterate over all warped Sentinel-2 TCI files to check the image quality on screen\n","for i, warpfile in enumerate(warpfiles):\n","  print(warpfile)\n","\n","  # make the filename of the new zoom image file\n","  clipfile = warpfile.split(\".\")[0] + \"_clip.tif\"\n","  clipfiles.append(clipfile) # remember the zoom file name in our list\n","  print(\"Clipped file: \", clipfile)\n","\n","  # clip it to the shapefile extent\n","  pygge.easy_clip(warpfile, clipfile, extent)\n","\n","# make maps\n","if len(clipfiles) == 1:\n","  pygge.easy_plot(clipfile, ax, bands=[1,2,3], percentiles=[0,100],\n","                  shapefile=shapefile, linecolor=\"yellow\", \n","                  title = clipfile.split(\"/\")[-1].split(\".\")[0], fontsize=8)\n","else:\n","  for i, clipfile in enumerate(clipfiles):\n","    pygge.easy_plot(clipfile, ax[i], bands=[1,2,3], percentiles=[0,100],\n","                  shapefile=shapefile, linecolor=\"yellow\", \n","                  title = clipfile.split(\"/\")[-1].split(\".\")[0], fontsize=8)\n","    \n","os.chdir(quickdir)\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wNHJ320VpfeK"},"source":["Before we end this session, we want to copy our downloaded Sentinel-2 data from Colab to Google Drive where the data will not be lost when this virtual machine terminates.\n","\n","You could do it via the Linux command line like this:\n","\n","```\n","!cp -r '/content/work/download' '/content/drive/MyDrive/practicals21-22'\n","```\n","\n","Or in a more pythonic way using the shutil library. The copytree function copies a directory and all its contents to a destination folder.\n"]},{"cell_type":"code","metadata":{"id":"kngN9aIeoerP"},"source":["# Copy the content of the download directory we created in Colab on a temporary drive\n","#    to the Google Drive partition, where it is not deleted when this session ends\n","\n","# name of our new directory on Google Drive\n","# NOTE THAT THIS WILL BE DELETED AND OVERWRITTEN!\n","target_dir = \"/content/drive/MyDrive/practicals21-22/download\"\n","\n","def copy_and_overwrite(from_path, to_path, delete_target_dir=True):\n","  '''\n","  Modified from: https://stackoverflow.com/questions/12683834/how-to-copy-directory-recursively-in-python-and-overwrite-all\n","  '''\n","  if os.path.exists(to_path):\n","    if delete_target_dir:\n","      shutil.rmtree(to_path)\n","      shutil.copytree(from_path, to_path)\n","    else:\n","      print(\"Error: Target directory exists and delete_target_dir is set to False.\")\n","  else:\n","    shutil.copytree(from_path, to_path)\n","  return()\n","\n","temp = copy_and_overwrite(downloaddir, target_dir, delete_target_dir=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"irJ95oIuEpWy"},"source":["#Formative assignment of this week\n","\n","In a new code cell below, download a Sentinel-2 image of the town you were born in. Produce a true colour image (TCI) map of the image, zooming into the area so you can see sufficient detail in the map. You can use the pygge.easy_plot function to do this."]},{"cell_type":"code","metadata":{"id":"lXa4LHiogwFI"},"source":[""],"execution_count":null,"outputs":[]}]}