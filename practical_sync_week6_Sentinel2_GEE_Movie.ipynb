{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "practical_sync_week6_Sentinel2_GEE_Movie.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUexW0CmhlF3"
      },
      "source": [
        "# Week 6: Accessing satellite data from Google Earth Engine from Python\n",
        "\n",
        "Individual learning outcomes: At the end of this week, all students should be able to access Sentinel-2 image composites from Google Earth Engine via the Python API, set up and submit a data query, download the data to Google Drive and Colab, and create a movie from a time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1skim1-_4qGc"
      },
      "source": [
        "# Get a user account for Google Earth Engine\n",
        "\n",
        "Before we begin, make sure to register for an account.\n",
        "\n",
        "For registration follow the link to the Open Access Hub and register: https://signup.earthengine.google.com/#!/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw0EK7xK_22r"
      },
      "source": [
        "In previous weeks, we had manually uploaded a Sentinel-2 image to our Google Drive directory.\n",
        "\n",
        "Today, we want to access Sentinel-2 imagery from Google Earth Engine (GEE) and search for available images over an area of interest of our choice. GEE allows users to submit a processing request. This is different from just accessing data, as it allows the user to request image composites that are aggregated from several different individual image takes from different dates, and the user can define the area for the download."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcro81WxTf4_"
      },
      "source": [
        "# Accessing Sentinel-2 images\n",
        "\n",
        "Workflow for this practical:\n",
        "* Define an area of interest based on an ESRI shapefile\n",
        "* Define a time window for our data search\n",
        "* Set a maximum acceptable cloud cover for our search\n",
        "* Use Google Earth Engine to make temporal composites of available images for selected spectral bands\n",
        "* Download them to your Google Drive\n",
        "* Reproject (warp) the images to the projection of the shapefile\n",
        "* Plot maps of the images\n",
        "* Make a movie for our area of interest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "___N_2vyp_f2"
      },
      "source": [
        "Connect to our Google Drive from Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RvpK17wXp_f7"
      },
      "source": [
        "# Load the Drive helper and mount your Google Drive as a drive in the virtual machine\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMCt1egJyZpv"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmglHMgnXhGw"
      },
      "source": [
        "#import required libraries\n",
        "!pip install earthengine-api\n",
        "!pip install requests\n",
        "!pip install rasterio\n",
        "!pip install geopandas\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio import plot\n",
        "from rasterio.plot import show_hist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from osgeo import gdal, ogr\n",
        "import json\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "import math\n",
        "from pprint import pprint\n",
        "import shutil\n",
        "import sys\n",
        "import zipfile\n",
        "import requests\n",
        "import io\n",
        "import webbrowser\n",
        "import ee\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0-BMbjnTf5K"
      },
      "source": [
        "# Set up some directory paths on Google Drive\n",
        "Modify these string variables to match your data directory structure if need be.\n",
        "\n",
        "BEFORE YOU RUN THIS CELL, EDIT THE VARIABLE wd BELOW TO POINT TO YOUR DIRECTORY ON GOOGLE DRIVE\n",
        "\n",
        "IMPORTANT: You must upload a shapefile of your area of interest to your Google Drive before running the next cell. Set the variable 'shapefile' below to point to this file. You can draw a polygon and save it as a shapefile on http://www.geojson.io."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzmlF4GQD1ji"
      },
      "source": [
        "# set up your directories for the satellite data\n",
        "# Note that we do all the downloading and data analysis on the temporary drive\n",
        "#    on Colab. We will copy the output directory to our Google Drive at the end.\n",
        "#    Colab has more disk space (about 40 GB free space) than Google Drive (15 GB).\n",
        "#    However, the data on the Colab disk space are NOT kept when you log out.\n",
        "\n",
        "# path to your Google Drive\n",
        "# EDIT THIS LINE (/content/drive/My Drive is the top directory on Google Drive):\n",
        "wd = \"/content/drive/MyDrive/practicals20-21\"\n",
        "print(\"Connected to data directory: \" + wd)\n",
        "\n",
        "# path to your temporary drive on the Colab Virtual Machine\n",
        "cd = \"/content/work\"\n",
        "\n",
        "# directory for downloading the Sentinel-2 composites\n",
        "# Note that we are using the 'join' function imported from the os library here\n",
        "# It is an easy way of merging strings into a directory structure.\n",
        "# It is clever and chooses the / or \\ depending on whether you are on Windows or Linux.\n",
        "downloaddir = join(cd, 'download') # where we save the downloaded images\n",
        "\n",
        "# CAREFUL: This code removes the named directories and everything inside them to free up space\n",
        "# Note: shutil provides a lot of useful functions for file and directory management\n",
        "try:\n",
        "  shutil.rmtree(downloaddir)\n",
        "except:\n",
        "  print(downloaddir + \" not found.\")\n",
        "\n",
        "# create the new directories, unless they already exist\n",
        "os.makedirs(cd, exist_ok=True)\n",
        "os.makedirs(downloaddir, exist_ok=True)\n",
        "\n",
        "print(\"Connected to Colab temporary data directory: \" + cd)\n",
        "\n",
        "print(\"\\nList of contents of \" + wd)\n",
        "for f in sorted(os.listdir(wd)):\n",
        "  print(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYU_0NnEyiSP"
      },
      "source": [
        "# Define our search parameters\n",
        "\n",
        "You can modify some of the parameters and upload your own shapefile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy8PKeYGTf5Q"
      },
      "source": [
        "# EDIT THE SEARCH OPTIONS BELOW\n",
        "\n",
        "# YOU CAN PLACE A DIFFERENT SHAPEFILE ONTO YOUR GOOGLE DRIVE BUT MAKE SURE THAT\n",
        "#    THE VARIABLE shapefile POINTS TO THE CORRECT FILE:\n",
        "shapefile = join(wd, 'oakham', 'Polygons_small.shp') # ESRI Shapefile of the study area\n",
        "\n",
        "# Define a date range for our search\n",
        "datefrom = '2019-03-01' # start date for imagery search\n",
        "dateto   = '2019-04-30' # end date for imagery search\n",
        "time_range = [datefrom, dateto] # format as a list\n",
        "\n",
        "# Define which cloud cover we accept in the images\n",
        "clouds = 10 # maximum acceptable cloud cover in %"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qoXgH7ioLRi"
      },
      "source": [
        "To make efficient use of Google Earth Engine from Python, we want to define some useful helper functions from https://climada-python.readthedocs.io/en/stable/tutorial/climada_util_earth_engine.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSWrk8Avcex7"
      },
      "source": [
        "# Functions modified from climada.util.earth_engine module\n",
        "def obtain_image_landsat_composite(collection, time_range, area):\n",
        "    \"\"\" Selection of Landsat cloud-free composites in the Earth Engine library\n",
        "    See also: https://developers.google.com/earth-engine/landsat\n",
        "\n",
        "    Parameters:\n",
        "        collection (): name of the collection\n",
        "        time_range (['YYYY-MT-DY','YYYY-MT-DY']): must be inside the available data\n",
        "        area (ee.geometry.Geometry): area of interest\n",
        "\n",
        "    Returns:\n",
        "        image_composite (ee.image.Image)\n",
        "     \"\"\"\n",
        "    collection = ee.ImageCollection(collection)\n",
        "\n",
        "    ## Filter by time range and location\n",
        "    collection_time = collection.filterDate(time_range[0], time_range[1])\n",
        "    image_area = collection_time.filterBounds(area)\n",
        "    image_composite = ee.Algorithms.Landsat.simpleComposite(image_area, 75, 3)\n",
        "    return image_composite\n",
        "\n",
        "def obtain_image_median(collection, time_range, area):\n",
        "    \"\"\" Selection of median from a collection of images in the Earth Engine library\n",
        "    See also: https://developers.google.com/earth-engine/reducers_image_collection\n",
        "\n",
        "    Parameters:\n",
        "        collection (): name of the collection\n",
        "        time_range (['YYYY-MT-DY','YYYY-MT-DY']): must be inside the available data\n",
        "        area (ee.geometry.Geometry): area of interest\n",
        "\n",
        "    Returns:\n",
        "        image_median (ee.image.Image)\n",
        "     \"\"\"\n",
        "    collection = ee.ImageCollection(collection)\n",
        "\n",
        "    ## Filter by time range and location\n",
        "    collection_time = collection.filterDate(time_range[0], time_range[1])\n",
        "    image_area = collection_time.filterBounds(area)\n",
        "    image_median = image_area.median()\n",
        "    return image_median\n",
        "\n",
        "'''\n",
        "The function below has been modified to accept the cloud cover threshold as an input\n",
        "'''\n",
        "def obtain_image_sentinel(collection, time_range, area, clouds):\n",
        "    \"\"\" Selection of median, cloud-free image from a collection of images in the Sentinel 2 dataset\n",
        "    See also: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2\n",
        "\n",
        "    Parameters:\n",
        "        collection (): name of the collection\n",
        "        time_range (['YYYY-MT-DY','YYYY-MT-DY']): must be inside the available data\n",
        "        area (ee.geometry.Geometry): area of interest\n",
        "\n",
        "    Returns:\n",
        "        sentinel_median (ee.image.Image)\n",
        "     \"\"\"\n",
        "#First, method to remove cloud from the image\n",
        "    def maskclouds(image):\n",
        "        band_qa = image.select('QA60')\n",
        "        cloud_mask = ee.Number(2).pow(10).int()\n",
        "        cirrus_mask = ee.Number(2).pow(11).int()\n",
        "        mask = band_qa.bitwiseAnd(cloud_mask).eq(0) and(\n",
        "            band_qa.bitwiseAnd(cirrus_mask).eq(0))\n",
        "        return image.updateMask(mask).divide(10000)\n",
        "\n",
        "    sentinel_filtered = (ee.ImageCollection(collection).\n",
        "                         filterBounds(area).\n",
        "                         filterDate(time_range[0], time_range[1]).\n",
        "                         filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', clouds)).\n",
        "                         map(maskclouds))\n",
        "\n",
        "    sentinel_median = sentinel_filtered.median()\n",
        "    return sentinel_median\n",
        "\n",
        "def get_region(geom):\n",
        "    \"\"\"Get the region of a given geometry, needed for exporting tasks.\n",
        "\n",
        "    Parameters:\n",
        "        geom (ee.Geometry, ee.Feature, ee.Image): region of interest\n",
        "\n",
        "    Returns:\n",
        "        region (list)\n",
        "    \"\"\"\n",
        "    if isinstance(geom, ee.Geometry):\n",
        "        region = geom.getInfo()[\"coordinates\"]\n",
        "    elif isinstance(geom, ee.Feature, ee.Image):\n",
        "        region = geom.geometry().getInfo()[\"coordinates\"]\n",
        "    elif isinstance(geom, list):\n",
        "        condition = all([isinstance(item) == list for item in geom])\n",
        "        if condition:\n",
        "            region = geom\n",
        "    return region\n",
        "\n",
        "def get_url(name, image, scale, region, filePerBand=False):\n",
        "    \"\"\"It will open and download automatically a zip folder containing Geotiff data of 'image'.\n",
        "    Parameters:\n",
        "        name -  a base name to use when constructing filenames.\n",
        "        image (ee.image.Image): image to export\n",
        "        scale (int): resolution of export in meters (e.g: 30 for Landsat)\n",
        "        region (list): region of interest\n",
        "        filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
        "            Defaults to true. If false, a single GeoTIFF is produced and all\n",
        "            band-level transformations will be ignored.\n",
        "\n",
        "    Returns:\n",
        "        path (str)\n",
        "\n",
        "\n",
        "    If additional parameters are needed, see also:\n",
        "    https://github.com/google/earthengine-api/blob/master/python/ee/image.py\n",
        "\n",
        "    Args:\n",
        "        params: An object containing visualization options with the following\n",
        "          possible values:\n",
        "        name -  a base name to use when constructing filenames.\n",
        "        bands -  a description of the bands to download. Must be an array of\n",
        "            dictionaries, each with the following keys:\n",
        "          id -  the name of the band, a string, required.\n",
        "          crs -  an optional CRS string defining the band projection.\n",
        "          crs_transform -  an optional array of 6 numbers specifying an affine\n",
        "              transform from the specified CRS, in the order: xScale, yShearing,\n",
        "              xShearing, yScale, xTranslation and yTranslation.\n",
        "          dimensions -  an optional array of two integers defining the width and\n",
        "              height to which the band is cropped.\n",
        "          scale -  an optional number, specifying the scale in meters of the\n",
        "                 band; ignored if crs and crs_transform is specified.\n",
        "        crs -  a default CRS string to use for any bands that do not explicitly\n",
        "            specify one.\n",
        "        crs_transform -  a default affine transform to use for any bands that do\n",
        "            not specify one, of the same format as the crs_transform of bands.\n",
        "        dimensions -  default image cropping dimensions to use for any bands\n",
        "            that do not specify them.\n",
        "        scale -  a default scale to use for any bands that do not specify one;\n",
        "            ignored if crs and crs_transform is specified.\n",
        "        region -  a polygon specifying a region to download; ignored if crs\n",
        "            and crs_transform is specified.\n",
        "        filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
        "            Defaults to true. If false, a single GeoTIFF is produced and all\n",
        "            band-level transformations will be ignored.\n",
        "     \"\"\"\n",
        "    path = image.getDownloadURL({\n",
        "        'name':(name),\n",
        "        'scale': scale,\n",
        "        'region':(region),\n",
        "        'filePerBand': (filePerBand)\n",
        "        })\n",
        "\n",
        "    webbrowser.open_new_tab(path)\n",
        "    return path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVsHiXZFeUnC"
      },
      "source": [
        "# Authenticate to the Google Earth Engine API.\n",
        "\n",
        "API stands for 'application programming interface'. An API defines interactions between multiple software intermediaries, in this case between our Jupyter Notebook and the ESA Copernicus Data Hub. It defines the kinds of calls or requests that can be made, how to make them, the data formats that should be used, the conventions to follow etc. (text modified after Wikipedia)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVhdO4CYNXf4"
      },
      "source": [
        "# Connect to Google Earth Engine API\n",
        "# This will open a web page where you have to enter your account information and a code is provided. Paste it in the terminal.\n",
        "!earthengine authenticate\n",
        "\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFWXZq5TzLhr"
      },
      "source": [
        "Get some information about our shapefile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDXQnbChE0b3"
      },
      "source": [
        "# Get the shapefile layer's extent\n",
        "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
        "ds = driver.Open(shapefile, 0)\n",
        "lyr = ds.GetLayer()\n",
        "extent = lyr.GetExtent()\n",
        "print(\"Extent of the area of interest (shapefile):\\n\", extent)\n",
        "print(type(extent))\n",
        "\n",
        "# get projection information of the shapefile\n",
        "outSpatialRef = lyr.GetSpatialRef().ExportToWkt()\n",
        "ds = None # close file\n",
        "print(\"\\nSpatial referencing information of the shapefile:\\n\", outSpatialRef)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAnLtG3HzPOj"
      },
      "source": [
        "Get the extent of the shapefile into a format that Google Earth Engine understands.\n",
        "\n",
        "Look at the printed outputs of the type conversions. The code will make more sense then."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tOoBk83HgsG"
      },
      "source": [
        "# GEE needs a special format for defining an area of interest. \n",
        "# It has to be a GeoJSON Polygon and the coordinates should be first defined in a list and then converted using ee.Geometry. \n",
        "extent_list = list(extent)\n",
        "print(extent_list)\n",
        "print(type(extent_list))\n",
        "# close the list of polygon coordinates by adding the starting node at the end again\n",
        "# and make list elements in the form of coordinate pairs (y,x)\n",
        "area_list = list([(extent[0], extent[2]),(extent[1], extent[2]),(extent[1], extent[3]),(extent[0], extent[3]),(extent[0], extent[2])])\n",
        "print(area_list)\n",
        "print(type(area_list))\n",
        "\n",
        "search_area = ee.Geometry.Polygon(area_list)\n",
        "print(search_area)\n",
        "print(type(search_area))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx4KzrZSzcyR"
      },
      "source": [
        "Now we can access the Sentinel-2 collection on Google Earth Engine and run our search. This will return a URL (web link) from which we can download the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsv6J_uMYBCI"
      },
      "source": [
        "# Obtain download links for image composites from an image collection on Google Earth Engine\n",
        "# All products available are detailed on this page https://developers.google.com/earth-engine/datasets/.\n",
        "\n",
        "# Name of the Sentinel 2 image collection\n",
        "s2collection = ('COPERNICUS/S2')\n",
        "\n",
        "# do the search on Google Earth Engine\n",
        "s2median = obtain_image_sentinel(s2collection, time_range, search_area, clouds)\n",
        "\n",
        "# to save disk space, we may want to download only certain bands\n",
        "# band names for download, a list of strings\n",
        "# only download R,G,B and NIR bands\n",
        "bands = ['B2', 'B3', 'B4', 'B8']\n",
        "print(bands)\n",
        "\n",
        "# spatial resolution of the downloaded data\n",
        "resolution = 20 # in units of metres\n",
        "\n",
        "# Download images in Geotiff, using the get_url(name, image, scale, region) method\n",
        "# ‘region’ is obtained from the area, but the format has to be adjusted using get_region(geom) method\n",
        "search_region = get_region(search_area)\n",
        "s2url = get_url('s2', s2median.select(bands), resolution, search_region, filePerBand=False)\n",
        "print(s2url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuMH8InRsMta"
      },
      "source": [
        "# Download the data\n",
        "\n",
        "The next cell downloads the image composite as a zip file and unzips it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDwSJ9EwUafJ"
      },
      "source": [
        "# change directory to download directory\n",
        "os.chdir(downloaddir)\n",
        "\n",
        "# request information on the file to be downloaded\n",
        "f = requests.get(s2url, stream =True)\n",
        "\n",
        "# check whether it is a zip file\n",
        "check = zipfile.is_zipfile(io.BytesIO(f.content))\n",
        "\n",
        "# either download the file as is, or unzip it\n",
        "while not check:\n",
        "    f = requests.get(s2url, stream =True)\n",
        "    check = zipfile.is_zipfile(io.BytesIO(f.content))\n",
        "else:\n",
        "    z = zipfile.ZipFile(io.BytesIO(f.content))\n",
        "    z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlB0QLm__yXX"
      },
      "source": [
        "# Explore the data directory structure of our downloaded files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ0b3ZURLOdm"
      },
      "source": [
        "# where we stored the downloaded Sentinel-2 images\n",
        "os.chdir(downloaddir)\n",
        "print(\"contents of \", downloaddir, \":\")\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfhMGieE5iS8"
      },
      "source": [
        "You should see the downloaded file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrSJL471MrcD"
      },
      "source": [
        "Remember that we have saved the downloaded images to a temporary directory that will be deleted when we close the virtual machine. If you want to save your images to your local directory, this is how it goes.\n",
        "\n",
        "Go to your Google Colab  folder in the panel on the left hand side.\n",
        "\n",
        "Find the download directory and click on a Sentinel-2 image folder.\n",
        "\n",
        "Right-click on it and select 'download' to save it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJp7NfpL_1bf"
      },
      "source": [
        "# Show the image as a true colour composite\n",
        "\n",
        "A true colour composite is a visualisation where the red, green and blue channels of the sensors are shown in the same colour on screen. Let's visualise our data composite in this way.\n",
        "\n",
        "First, let's see what tiff files are in our directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCwuRpEJLS4E"
      },
      "source": [
        "# get list of all tiff files in the directory\n",
        "allfiles = [f for f in listdir(downloaddir) if isfile(join(downloaddir, f))]\n",
        "print(allfiles)\n",
        "\n",
        "# select the file for visualisation\n",
        "thisfile = allfiles[0]\n",
        "print(thisfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxhvZZe2UmCu"
      },
      "source": [
        "Now we know which image files we want to show on screen, the rest is easy. Just like last week.\n",
        "\n",
        "Use our handy plotting function.\n",
        "We modify it such that it is able to exclude the lowest and highest pixel values from each band separately using the NumPy percentile function as an option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRzVmBLO8REB"
      },
      "source": [
        "def tci(afile, ax=None, bands=[3,2,1], percentiles=[0,100], xlim=None, ylim=None): \n",
        "  # tci stands for true colour image\n",
        "  # afile is a handle to an image file opened with RasterIO.Open()\n",
        "  # ax is the axes handle to plot the map on\n",
        "  # bands is the order of image bands in the source file to become RGB channels\n",
        "  # percentiles = list of percentiles for trimming the histogram\n",
        "  #    [0,100] stands for min, max\n",
        "  # xlim =[xmin, xmax] is the map extent to be shown in x direction\n",
        "  # ylim =[ymin, ymax] is the map extent to be shown in y direction\n",
        "  \n",
        "  # we define a function within this function:\n",
        "  def scale_to_uint8(x, percentiles=[0,100]):\n",
        "    # scale array x to 0-255 and convert to uint8\n",
        "    # x = input array\n",
        "    # percentiles = list of percentiles for trimming the histogram\n",
        "    #    [0,1] stands for min, max\n",
        "    x = np.float32(x)\n",
        "    amin = np.percentile(x, percentiles[0])\n",
        "    amax = np.percentile(x, percentiles[1])\n",
        "    anewmin = 0.0\n",
        "    anewmax = 255.0\n",
        "    xscaled = (x - amin) * ((anewmax - anewmin) / (amax - amin)) + anewmin\n",
        "    return(xscaled.astype(np.uint8))\n",
        "\n",
        "  # save the uint8 image as a temporary Geotiff file\n",
        "  tmpfile = rasterio.open('tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff',\n",
        "                            'w',driver='Gtiff', width=afile.width, height=afile.height,\n",
        "                            count=3, crs=afile.crs, transform=afile.transform, \n",
        "                            dtype=np.uint8)\n",
        "\n",
        "  # mask out extreme values for each band\n",
        "  for b in range(3):\n",
        "    # read band data\n",
        "    a = afile.read(bands[b])\n",
        "    a_uint8 = scale_to_uint8(a, percentiles) \n",
        "    # write the output into the new file as band b+1\n",
        "    tmpfile.write(a_uint8, b+1)\n",
        "\n",
        "  # close the file\n",
        "  tmpfile.close()\n",
        "\n",
        "  # try plotting the image\n",
        "  imgfile = rasterio.open(r'tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff', count=3)\n",
        "\n",
        "  if (xlim==None):\n",
        "    xlim=[afile.bounds.left, afile.bounds.right]\n",
        "    # afile.bounds returns a BoundingBox(left, bottom, right, top) object,\n",
        "    #    from which we need to get the corner coordinates like so\n",
        "\n",
        "  if (ylim==None):\n",
        "    ylim=[afile.bounds.bottom, afile.bounds.top]\n",
        "  \n",
        "  # zoom in to an area of interest by setting the axes limits of our map\n",
        "  ax.set_xlim(xlim)\n",
        "  ax.set_ylim(ylim)\n",
        "  plot.show(imgfile, ax=ax)\n",
        "\n",
        "  # close the temporary file\n",
        "  imgfile.close()\n",
        "\n",
        "  # and remove the temporary file when we do not need it anymore\n",
        "  os.remove('tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff')\n",
        "\n",
        "  return()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvnzMaX409dr"
      },
      "source": [
        "The visualisation function is now defined and Python understands it when we call it. Now we can execute it and show our downloaded data on screen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaCimAhcUlFz"
      },
      "source": [
        "# open file\n",
        "f = rasterio.open(thisfile, 'r') \n",
        "\n",
        "# create a figure with 2x3 subplots\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(10,16))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# the downloaded file is float32 data format\n",
        "# for plotting, we need uint8 data format\n",
        "\n",
        "# plot the image with full extent\n",
        "tci(f, ax=ax1, percentiles=[0,98])\n",
        "\n",
        "# zoom in to an area of interest\n",
        "xlim=[-0.75, -0.70] # longitude coordinates\n",
        "ylim=[52.66, 52.68] # latitude coordinates\n",
        "tci(f, ax=ax2, percentiles=[0,98], xlim=xlim, ylim=ylim)\n",
        "\n",
        "# zoom in elsewhere\n",
        "xlim=[-0.70, -0.60]\n",
        "ylim=[52.63, 52.68]\n",
        "tci(f, ax=ax3, percentiles=[0,98], xlim=xlim, ylim=ylim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIpqcW9a8Fnu"
      },
      "source": [
        "Users of data often want the results in their own geographic projection.\n",
        "\n",
        "Let's warp the images to the same projection as the shapefile. \n",
        "\n",
        "Remember we did this last week:\n",
        "\n",
        "```\n",
        "ds = gdal.Warp('Sentinel-2_stack_100m_BNG.tiff',\n",
        "               'Sentinel-2_stack_100m.tiff', dstSRS='EPSG:27700')\n",
        "ds = None #remember to close and save the output file\n",
        "```\n",
        "\n",
        "So let's put GDAL to work.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SziStT4I8L0p"
      },
      "source": [
        "# get the spatial referencing system of our shapefile into which we want to reproject the TCI images\n",
        "# remember, we did this when we opened the shapefile earlier and saved it in outSpatialRef\n",
        "print(\"Reprojecting image to the following projection:\")\n",
        "print(outSpatialRef)\n",
        "\n",
        "# make a file name for our new file\n",
        "warpfile = thisfile.split(sep='.')[0] + '_warped.tif'\n",
        "\n",
        "# check whether the warp file already exists and skip if it does\n",
        "if not os.path.exists(warpfile):\n",
        "  # call the GDAL Warp command\n",
        "  ds = gdal.Warp(warpfile, thisfile, dstSRS=outSpatialRef)\n",
        "  ds = None #remember to close and save the output file\n",
        "else:\n",
        "  print(\"warped file already exists\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMT7Y0Q1O81"
      },
      "source": [
        "# Plot the shapefile on top of the raster\n",
        "\n",
        "Suppose we want to see the locations of our polygons on top of our image composite. We can do that with the Geopandas library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm_DVizqkATe"
      },
      "source": [
        "# open the warped image\n",
        "f = rasterio.open(warpfile, 'r') \n",
        "\n",
        "# create a figure with 2x3 subplots\n",
        "fig, ax = plt.subplots(3,1, figsize=(10,16))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# Remember, the warped file is float32 data format\n",
        "# for plotting, we need uint8 data format\n",
        "\n",
        "# plot the image with full extent\n",
        "tci(f, ax=ax[0], percentiles=[0,98])\n",
        "\n",
        "# zoom in to an area of interest\n",
        "xlim=[-0.75, -0.70]\n",
        "ylim=[52.66, 52.68]\n",
        "tci(f, ax=ax[1], percentiles=[0,98], xlim=xlim, ylim=ylim)\n",
        "\n",
        "# zoom in elsewhere\n",
        "xlim=[-0.70, -0.60]\n",
        "ylim=[52.63, 52.68]\n",
        "tci(f, ax=ax[2], percentiles=[0,98], xlim=xlim, ylim=ylim)\n",
        "\n",
        "# We will use the Geopandas library for plotting the shapefile on top of the raster image.\n",
        "shp = gpd.read_file(shapefile)\n",
        "# add the shapefile to all three images\n",
        "for i in range(3):\n",
        "  shp.plot(ax=ax[i], facecolor=\"none\", edgecolor=\"yellow\")\n",
        "  # set a title for the subplot\n",
        "  mytitle = \"Title\"\n",
        "  ax[i].set_title(mytitle, fontsize=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCo-c2l6_75f"
      },
      "source": [
        "# Make a movie from several Sentinel-2 image composites\n",
        "\n",
        "To analyse several images, we can simply repeat the API query and download temporal composites. These are made automatically by Google Earth Engine. In our case, we want to calculate the median reflectance of all pixel values that are cloud-free, aggregated by month.\n",
        "\n",
        "For this task, we copy and paste the code from above into a single cell (below), and iterate over the different months for our searches. The for loop does the job for us.\n",
        "\n",
        "We will use the imageio library to make a movie from the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbFW6LuqSR_Q"
      },
      "source": [
        "# Obtain monthly image composites\n",
        "\n",
        "# change directory to download directory\n",
        "os.chdir(downloaddir)\n",
        "\n",
        "# make a list of lists with all date ranges for our new searches\n",
        "months = [['2020-01-01', '2020-01-31'],\n",
        "          ['2020-02-01', '2020-02-29'],\n",
        "          ['2020-03-01', '2020-03-31'],\n",
        "          ['2020-04-01', '2020-04-30'],\n",
        "          ['2020-05-01', '2020-05-31'],\n",
        "          ['2020-06-01', '2020-06-30'],\n",
        "          ['2020-07-01', '2020-07-31'],\n",
        "          ['2020-08-01', '2020-08-31'],\n",
        "          ['2020-09-01', '2020-09-30'],\n",
        "          ['2020-10-01', '2020-10-31']]\n",
        "\n",
        "# set cloud cover threshold\n",
        "clouds = 30\n",
        "\n",
        "# band names for download, a list of strings\n",
        "# only download R,G,B and NIR bands\n",
        "bands = ['B2', 'B3', 'B4', 'B8']\n",
        "\n",
        "# spatial resolution of the downloaded data\n",
        "resolution = 20 # in units of metres\n",
        "\n",
        "# iterate over the months\n",
        "for month in range(len(months)):\n",
        "  time_range = months[month]\n",
        "  print(time_range)\n",
        "\n",
        "  # do the search on Google Earth Engine\n",
        "  s2median = obtain_image_sentinel(s2collection, time_range, search_area, clouds)\n",
        "  print(type(s2median))\n",
        "\n",
        "  # print out the band names of the image composite that was returned by our search\n",
        "  band_names = s2median.bandNames().getInfo()\n",
        "  print(band_names)\n",
        "\n",
        "  # check whether the search returned any imagery\n",
        "  if len(band_names) == 0:\n",
        "\n",
        "    print(\"Search returned no results.\")\n",
        "\n",
        "  # if there are band names in our search results, proceed\n",
        "  else:\n",
        "    \n",
        "    # begin the file name with this ID\n",
        "    file_id = 's2_month'\n",
        "    \n",
        "    s2url = get_url(file_id+\"{0:3d}\".format(month+1), s2median.select(bands), resolution, search_region, filePerBand=False)\n",
        "    print(s2url)\n",
        "\n",
        "    # request information on the file to be downloaded\n",
        "    f = requests.get(s2url, stream =True)\n",
        "\n",
        "    # check whether it is a zip file\n",
        "    check = zipfile.is_zipfile(io.BytesIO(f.content))\n",
        "\n",
        "    # either download the file as is, or unzip it\n",
        "    while not check:\n",
        "        f = requests.get(s2url, stream =True)\n",
        "        check = zipfile.is_zipfile(io.BytesIO(f.content))\n",
        "    else:\n",
        "        z = zipfile.ZipFile(io.BytesIO(f.content))\n",
        "        z.extractall()\n",
        "\n",
        "# after downloading all image composites, get a list of all files we want to warp\n",
        "allfiles = [f for f in listdir(downloaddir) if isfile(join(downloaddir, f))]\n",
        "files_for_warp = [s for s in allfiles if file_id in s]\n",
        "print(\"Files for warping:\")\n",
        "pprint(sorted(files_for_warp))\n",
        "\n",
        "# now warp them all\n",
        "for f in files_for_warp:\n",
        "  # make a file name for our new file\n",
        "  warpfile = f.split('.')[0]+'_warped.tif'\n",
        "  # call the GDAL Warp command\n",
        "  ds = gdal.Warp(warpfile, f, dstSRS=outSpatialRef)\n",
        "  ds = None #remember to close and save the output file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqpYT7qF2ADw"
      },
      "source": [
        "Get all images into the same projection as the shapefile using GDAL warp.\n",
        "\n",
        "Then save them as uint8 format for making the movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxJnsUdAc3lq"
      },
      "source": [
        "# after downloading and warping all image composites, get a list of all warped tiff files in the directory\n",
        "allfiles = [f for f in listdir(downloaddir) if isfile(join(downloaddir, f))]\n",
        "warpfiles = [s for s in allfiles if \"_warped.tif\" in s]\n",
        "print(\"Files after warping:\")\n",
        "pprint(sorted(warpfiles))\n",
        "\n",
        "# Remember, the warped file is float32 data format\n",
        "# for plotting, we need uint8 data format\n",
        "# We can adapt our previous tci function and take out the plotting but save the image data\n",
        "def save_as_uint8(afile, outfile, bands=[3,2,1], percentiles=[0,100]):\n",
        "  # afile is a handle to an image file opened with RasterIO.Open()\n",
        "  # outfile is the output file name\n",
        "  # percentiles = list of percentiles for trimming the histogram\n",
        "  #    [0,100] stands for min, max\n",
        "  # bands is the order of image bands in the source file to become RGB channels\n",
        "\n",
        "  def scale_to_uint8(x, percentiles=[0,100]):\n",
        "    # scale array x to 0-255 and convert to uint8\n",
        "    # x = input array\n",
        "    # percentiles = list of percentiles for trimming the histogram\n",
        "    #    [0,1] stands for min, max\n",
        "    x = np.float32(x)\n",
        "    amin = np.percentile(x, percentiles[0])\n",
        "    amax = np.percentile(x, percentiles[1])\n",
        "    anewmin = 0.0\n",
        "    anewmax = 255.0\n",
        "    xscaled = (x - amin) * ((anewmax - anewmin) / (amax - amin)) + anewmin\n",
        "    return(xscaled.astype(np.uint8))\n",
        "\n",
        "  # save the uint8 image as a temporary Geotiff file\n",
        "  outf = rasterio.open(outfile,'w',driver='Gtiff', width=afile.width, height=afile.height,\n",
        "                       count=3, crs=afile.crs, transform=afile.transform, dtype=np.uint8)\n",
        "\n",
        "  # mask out extreme values for each band\n",
        "  for b in range(3):\n",
        "    # read band data\n",
        "    a = afile.read(bands[b])\n",
        "    a_uint8 = scale_to_uint8(a, percentiles) \n",
        "    # write the output into the new file as band b+1\n",
        "    outf.write(a_uint8, b+1)\n",
        "\n",
        "  # close the file\n",
        "  outf.close()\n",
        "\n",
        "  return()\n",
        "\n",
        "# iterate over all warpfiles\n",
        "for w in sorted(warpfiles):\n",
        "  print(w)\n",
        "  wfile=rasterio.open(w, 'r')\n",
        "  # make a file name for our new file\n",
        "  outfile = w.split(sep='.')[0] + '_uint8.tif'\n",
        "  save_as_uint8(wfile, outfile)\n",
        "\n",
        "# get a list of all warped tiff files in uint8 data format in the directory\n",
        "allfiles = [f for f in listdir(downloaddir) if isfile(join(downloaddir, f))]\n",
        "uint8files = [s for s in allfiles if \"_warped_uint8.tif\" in s]\n",
        "pprint(sorted(uint8files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLqCXn0n2KmG"
      },
      "source": [
        "Now it is time to make the actual movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-U60XS6LWfo"
      },
      "source": [
        "import imageio\n",
        "# create an empty Numpy array where we will merge all raster images\n",
        "images = []\n",
        "# iterate over all zoom files\n",
        "for f in sorted(uint8files):\n",
        "  images.append(imageio.imread(f)) # read the next image and append it\n",
        "\n",
        "# Let's set the frame rate to 3 seconds.\n",
        "framerate = { 'duration': 3 }\n",
        "\n",
        "# save the movie\n",
        "imageio.mimsave(join(downloaddir, \"movie.gif\"), images, **framerate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXgp6Ogx1SvD"
      },
      "source": [
        "Now download the file movie.gif from Colab using the folder icon on the left hand side. Locate the file in the 'out' directory, right-click and select 'download'. \n",
        "\n",
        "Save it to your local hard drive and open it with Google Chrome to view it."
      ]
    }
  ]
}