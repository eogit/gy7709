{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy classification\n",
    "\n",
    "In this practical, we will read in a Sentinel-2 image from its original data format as obtained from the ESA Copernicus Sentinel Data Hub. We will extract four bands of interest and convert them to one single Geotiff file (the Sentinel-2 data are originally delivered as separate JPEG2000 files, one for each band).\n",
    "We will then train the Maximum Entropy algorithm.\n",
    "Finally, we will classify the Sentinel-2 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "# Note: GDAL needs to be version 2.1.3\n",
    "# from Anaconda terminal type:\n",
    "#    conda install -c conda-forge gdal\n",
    "\n",
    "import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from osgeo import ogr\n",
    "import shutil\n",
    "import skimage\n",
    "from skimage import io\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "#from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.externals import joblib\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything installed. Now onto the processing.\n",
    "The next block of code reads in the Sentinel-2 L2A (Level 2A) image obtained from the Copernicus Sentinel Data Hub.\n",
    "Sentinel images can be obtained for free from this web site: https://scihub.copernicus.eu/dhus/#/home\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/S2A_MSIL2A_20180507T110621_N0207_R137_T30UXD_20180507T131836.SAFE/GRANULE/L2A_T30UXD_A015006_20180507T110835/IMG_DATA/R10m\n",
      "T30UXD_20180507T110621_AOT_10m.jp2\n",
      "T30UXD_20180507T110621_B02_10m.jp2\n",
      "T30UXD_20180507T110621_B03_10m.jp2\n",
      "T30UXD_20180507T110621_B04_10m.jp2\n",
      "T30UXD_20180507T110621_B08_10m.jp2\n",
      "T30UXD_20180507T110621_TCI_10m.jp2\n",
      "T30UXD_20180507T110621_WVP_10m.jp2\n"
     ]
    }
   ],
   "source": [
    "# in this directory are the Sentinel-2, 20 m resolution band files\n",
    "# N.B. os.path.join uses the correct '\\' for Windows OS or '/' for LINUX\n",
    "datadir = join(os.sep, 'home', 'heiko', 'sf_GY7709_Satellite_Data_Analysis_in_Python', 'practicals', \\\n",
    "               'S2A_MSIL2A_20180507T110621_N0207_R137_T30UXD_20180507T131836.SAFE', 'GRANULE', \\\n",
    "               'L2A_T30UXD_A015006_20180507T110835', 'IMG_DATA', 'R10m')\n",
    "# e.g. /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/S2A_MSIL2A_20180507T110621_N0207_R137_T30UXD_20180507T131836.SAFE/GRANULE/L2A_T30UXD_A015006_20180507T110835/IMG_DATA/R10m\n",
    "\n",
    "# directory for output image files from MaxEnt\n",
    "outdir = join(os.sep, 'home', 'heiko', 'sf_GY7709_Satellite_Data_Analysis_in_Python', 'practicals')\n",
    "\n",
    "print('Files in directory ' + datadir)\n",
    "allfiles = [f for f in listdir(datadir) if isfile(join(datadir, f))]\n",
    "for f in allfiles:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have listed all files in the directory where the 10 m resolution bands of Sentinel-2 are located.\n",
    "Now, let's read in the bands we want.\n",
    "Sentinel-2 bands 2,3,4 and 8 are in the above file list in positions 1,2,3,4 (remember the first index in Python is 0).\n",
    "These bands are blue, green, red and NIR.\n",
    "\n",
    "Note: For this to work, GDAL requires the JP2OpenJPEG driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals16Bit.vrt  already exists.\n",
      "\n",
      "/home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals16Bit.tif  already exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a band selection\n",
    "bands = allfiles[1:5]\n",
    "# this gives a collection of the following file names:\n",
    "'''\n",
    "    {\"band_02\" :  inputPath + \"B02_10m.jp2\",\n",
    "     \"band_03\" :  inputPath + \"B03_10m.jp2\",\n",
    "     \"band_04\" :  inputPath + \"B04_10m.jp2\",\n",
    "     \"band_08\" :  inputPath + \"B08_10m.jp2\"}\n",
    "'''\n",
    "\n",
    "# build a command line command for GDAL to convert the files into 10 m resolution VRT format\n",
    "cmd = ['gdalbuildvrt', '-resolution', 'user', '-tr' ,'10', '10', '-separate', join(outdir + '16Bit.vrt')]\n",
    "for band in bands:\n",
    "    cmd.append(join(datadir, band))\n",
    "           \n",
    "vrtfile = join(outdir + '16Bit.vrt')\n",
    "if not os.path.exists(vrtfile): # skip if the output file already exists\n",
    "    print('\\n')\n",
    "    print(' '.join(cmd))\n",
    "    print('\\n')\n",
    "    subprocess.run(cmd) # execute the command in the command line\n",
    "else:\n",
    "    print(vrtfile,' already exists.\\n')\n",
    "    \n",
    "# now build a command to translate the four band raster files into one geotiff file with 4 bands\n",
    "tiffile = join(outdir + '16Bit.tif')\n",
    "cmd = ['gdal_translate', '-of' ,'GTiff', vrtfile, tiffile]\n",
    "\n",
    "if not os.path.exists(tiffile): # skip if the output file already exists\n",
    "    print(' '.join(cmd))\n",
    "    print('\\n')\n",
    "    subprocess.run(cmd) # execute it\n",
    "else:\n",
    "    print(tiffile,' already exists.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sentinel-2 data preparation is completed at this stage. We have the four bands we want in one Geotiff file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your portfolio task\n",
    "\n",
    "Open QGIS or ArcGIS and read in the tiff file. Take a look at the bands and make a true colour composite.\n",
    "Take a screenshot of the overview image, i.e. the whole extent. Add that to your portfolio.\n",
    "\n",
    "Now zoom in to the full resolution, take another screenshot of an area you find interesting and add it to your portfolio. \n",
    "\n",
    "Describe in text form (300 words) what you see. You can use arrows to annotate your images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the next step is the train the Maximum Entropy machine learning model. Remember that Maximum Entropy is also known as Logistic Regression.\n",
    "\n",
    "We will use the same training data as for the Random Forest practical.\n",
    "\n",
    "The code below is modified after the example by Arthur Mensch: https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_20newsgroups.html#sphx-glr-auto-examples-linear-model-plot-sparse-logistic-regression-20newsgroups-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data include 7 classes: [1 2 3 4 5 6 7]\n",
      "Dimensions of the clipped Sentinel-2 image:\n",
      "(3118, 4665, 4)\n"
     ]
    }
   ],
   "source": [
    "# ignore less important warnings in SciKit-Learn\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "\n",
    "# We use the SAGA solver\n",
    "solver = 'saga'\n",
    "\n",
    "# Reduce number of samples for faster run time\n",
    "n_samples = 3000\n",
    "\n",
    "# We train the MaxEnt algorithm on the clipped Sentinel-2 image. This has two reasons:\n",
    "# 1. It is faster to process.\n",
    "# 2. We already have the training data and clipped Sentinel-2 image from the Random Forest exercise.\n",
    "\n",
    "# set up your directories with the satellite training data\n",
    "rootdir = join(os.sep, \"home\", \"heiko\", \"sf_GY7709_Satellite_Data_Analysis_in_Python\", \"practicals\")\n",
    "# path to your training data\n",
    "path_pix = rootdir\n",
    "# path to your model\n",
    "path_model = rootdir\n",
    "# path to your classification results\n",
    "path_class = rootdir\n",
    "\n",
    "# path to your Sentinel-2 clipped TIFF file from the Random Forest exercise\n",
    "raster = join(rootdir, \"s2a_leicester_clipped.tif\")\n",
    "# path to your corresponding pixel samples (training data converted to a geotiff raster file)\n",
    "# pixel values are the class numbers\n",
    "samples = join(path_pix, \"training_raster.tif\")\n",
    "\n",
    "# read in clipped Sentinel-2A raster from geotiff (unsigned 16-bit integer format)\n",
    "# this was created in QGIS from the original Sentinel-2 10m bands (R,G,B,NIR)\n",
    "img_ds = io.imread(raster)\n",
    "# convert to 16bit numpy array \n",
    "img = np.array(img_ds, dtype='int16')\n",
    "\n",
    "# do the same with your training sample pixels \n",
    "roi_ds = io.imread(samples)   \n",
    "roi = np.array(roi_ds, dtype='int8')  \n",
    "    \n",
    "# read in your labels\n",
    "labels = np.unique(roi[roi > 0]) \n",
    "n_classes = labels.size\n",
    "print('The training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
    "\n",
    "# compose your X,Y data (dataset - training data)     \n",
    "X = img[roi > 0, :] \n",
    "Y = roi[roi > 0]     \n",
    "\n",
    "# print out the number of pixels, number of lines and number of bands of the image\n",
    "print(\"Dimensions of the clipped Sentinel-2 image:\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have read in the data to train the model.\n",
    "Let's read in the full Sentinel-2 image in its original extent from the Geotiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the full Sentinel-2 image:\n",
      "(10980, 10980, 4)\n"
     ]
    }
   ],
   "source": [
    "# Read in the full Sentinel-2 data from the Geotiff we have created above\n",
    "s2img = io.imread(tiffile) # returns an ndarray with all bands for all pixels\n",
    "\n",
    "# print out the number of pixels, number of lines and number of bands of the image\n",
    "print(\"Dimensions of the full Sentinel-2 image:\")\n",
    "print(s2img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: train the MaxEnt model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel-2, train_samples=96402, n_features=4, n_classes=7\n",
      "MaxEnt, solver=saga. Number of iterations: 10\n",
      "Test accuracy for MaxEnt model: 92.3355%\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "# Split the training data into 75% for training and 25% held back for testing the classification model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, stratify=Y, test_size=0.25)\n",
    "train_samples, n_features = x_train.shape\n",
    "print('Sentinel-2, train_samples=%i, n_features=%i, n_classes=%i' % (train_samples, n_features, n_classes))\n",
    "\n",
    "# A small number of iterations leads to faster run time\n",
    "max_iter = 10\n",
    "print('MaxEnt, solver=%s. Number of iterations: %s' % (solver, max_iter))\n",
    "# run the logistic regression, this is equivalent to maximum entropy modelling\n",
    "lr = LogisticRegression(solver=solver, multi_class='multinomial', C=1, penalty='l1', fit_intercept=True, max_iter=max_iter, random_state=42)\n",
    "# fit model to training data\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# export your Random Forest / Gradient Boosting Model     \n",
    "model = datadir + \"model_maxent.pkl\"\n",
    "joblib.dump(lr, model)\n",
    "\n",
    "# predict classes for each pixel of the testing data\n",
    "y_pred = lr.predict(x_test)\n",
    "accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n",
    "print('Test accuracy for MaxEnt model: %.4f%%' % (accuracy * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The output above gives the overall accuracy of the MaxEnt model for the testing data. Remember, we have held back a proportion of the training data (25% of all pixels) for testing the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 chunks of a Sentinel-2 image\n",
      "chunk  0  from pixel  0  to  12056039\n",
      "chunk  1  from pixel  12056040  to  24112079\n",
      "chunk  2  from pixel  24112080  to  36168119\n",
      "chunk  3  from pixel  36168120  to  48224159\n",
      "chunk  4  from pixel  48224160  to  60280199\n",
      "chunk  5  from pixel  60280200  to  72336239\n",
      "chunk  6  from pixel  72336240  to  84392279\n",
      "chunk  7  from pixel  84392280  to  96448319\n",
      "chunk  8  from pixel  96448320  to  108504359\n",
      "chunk  9  from pixel  108504360  to  120560399\n",
      "Opening file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals16Bit.tif\n",
      "File driver: GTiff/GeoTIFF\n",
      "Raster size: 10980 x 10980 x 4\n",
      "Projection: PROJCS[\"WGS 84 / UTM zone 30N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-3],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32630\"]]\n",
      "Origin = (600000.0, 5900040.0)\n",
      "Pixel Size = (10.0, -10.0)\n",
      "Creating output classification file: /home/heiko/sf_GY7709_Satellite_Data_Analysis_in_Python/practicals/landcover_maxent.tif\n",
      "(10980, 10980)\n"
     ]
    }
   ],
   "source": [
    "# Apply the MaxEnt model to the whole Sentinel-2 image\n",
    "# Classification of array and save as image (5 refers to the number of bands)\n",
    "# first, string out the image array into a long and thin shape for processing\n",
    "new_shape = (s2img.shape[0] * s2img.shape[1], s2img.shape[2]) \n",
    "img_as_array = s2img[:, :, :5].reshape(new_shape)\n",
    "\n",
    "# to save memory, process the Sentinel-2 scene in 10 chunks\n",
    "print(\"Processing 10 chunks of a Sentinel-2 image\")\n",
    "for chunk in range(0,10):\n",
    "    print(\"chunk \", chunk, \" from pixel \", (chunk * int(new_shape[0] / 10)), \" to \", ((chunk + 1) * int(new_shape[0] / 10)) - 1)\n",
    "    chunk_prediction = lr.predict(img_as_array[(chunk * int(new_shape[0] / 10)):((chunk + 1) * int(new_shape[0] / 10)), :int(new_shape[1])])\n",
    "    if chunk == 0:\n",
    "        class_prediction = list(chunk_prediction)\n",
    "    else:\n",
    "        class_prediction.extend(list(chunk_prediction))\n",
    "\n",
    "# convert list object to numpy array and bring back from a long and thin shape to an image shape\n",
    "class_prediction = np.array(class_prediction)\n",
    "class_prediction = class_prediction.reshape(s2img[:, :, 0].shape)  \n",
    "\n",
    "# add the geotransform - it contains projection information\n",
    "# Open the Sentinel-2 Geotiff file and read in the geographic extent, which is the same as for the classified map\n",
    "print(\"Opening file: {}\".format(tiffile))\n",
    "dataset = gdal.Open(tiffile, gdal.GA_ReadOnly)\n",
    "if not dataset:\n",
    "    print(\"Error. File not found.\")\n",
    "print(\"File driver: {}/{}\".format(dataset.GetDriver().ShortName, dataset.GetDriver().LongName))\n",
    "print(\"Raster size: {} x {} x {}\".format(dataset.RasterXSize, dataset.RasterYSize, dataset.RasterCount))\n",
    "wkt_projection = dataset.GetProjection()\n",
    "print(\"Projection: {}\".format(wkt_projection))\n",
    "geotransform = dataset.GetGeoTransform()\n",
    "if geotransform:\n",
    "    print(\"Origin = ({}, {})\".format(geotransform[0], geotransform[3]))\n",
    "    print(\"Pixel Size = ({}, {})\".format(geotransform[1], geotransform[5]))\n",
    "\n",
    "'''\n",
    "Contents of the GeoTransform:\n",
    "GeoTransform[0] /* top left x coordinate */\n",
    "GeoTransform[1] /* West to East pixel resolution in x direction */\n",
    "GeoTransform[2] /* 0 */\n",
    "GeoTransform[3] /* top left y coordinate */\n",
    "GeoTransform[4] /* 0 */\n",
    "GeoTransform[5] /* North to South pixel resolution in y direction (negative value) */\n",
    "'''\n",
    "\n",
    "# Create the destination data file\n",
    "classfilename = join(path_class, \"landcover_maxent.tif\")\n",
    "print(\"Creating output classification file: {}\".format(classfilename))\n",
    "# make the class file the same length and width like the Sentinel-2 image, but with only one band and as Byte values\n",
    "classfile = gdal.GetDriverByName('GTiff').Create(classfilename, s2img.shape[0], s2img.shape[1], 1, gdal.GDT_Byte)\n",
    "classfile.SetGeoTransform((geotransform[0], geotransform[1], 0, geotransform[3], 0, geotransform[5]))\n",
    "classfile.SetProjection(wkt_projection)\n",
    "\n",
    "print(class_prediction.shape)\n",
    "\n",
    "# now export your classification map to a file\n",
    "classfile.GetRasterBand(1).WriteArray(class_prediction)\n",
    "classfile.FlushCache()  # Write to disk.\n",
    "\n",
    "# All done, close the data file to free up memory\n",
    "classfile = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your portfolio task\n",
    "Open the classified map file in QGIS or ArcGIS and include an overview with a colour legend of the classes in your portfolio.\n",
    "\n",
    "Choose two areas of interest. Zoom in to full resolution. Add the zoom maps to the portfolio.\n",
    "\n",
    "Write about 300 words about what you see in your areas of interest. Reflect on whether the MaxEnt classification gives accurate and representative results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
