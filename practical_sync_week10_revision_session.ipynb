{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"practical_sync_week10_revision_session.ipynb","provenance":[{"file_id":"1gcFsTGzGG5CNNAZk2VLZB2_TQLCc6MoH","timestamp":1606416954130},{"file_id":"15AIJzS_uoHPaoO0tuefzEUCI2YC8oMEk","timestamp":1606308858503}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"XUexW0CmhlF3"},"source":["# Week 10: Revision session\n","\n","This session recaps on important learning outcomes from the whole module."]},{"cell_type":"markdown","metadata":{"id":"___N_2vyp_f2"},"source":["# Connecting to Google Drive from Colab"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"RvpK17wXp_f7"},"source":["# Load the Drive helper and mount your Google Drive as a drive in the virtual machine\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lxAdkqX7_ZZw"},"source":["# Import all necessary libraries"]},{"cell_type":"code","metadata":{"id":"HXnzg_pcTSEP"},"source":["#import required libraries\n","!pip install rasterio\n","!pip install sentinelsat\n","!pip install geopandas\n","!pip install rasterstats\n","\n","import csv \n","import geopandas as gpd\n","import math\n","from math import floor, ceil\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import ogr\n","import os\n","from os import listdir\n","from os.path import isfile, isdir, join\n","from osgeo import gdal\n","import pickle\n","from pyproj import Proj\n","from pprint import pprint\n","import rasterio\n","from rasterio.windows import Window\n","from rasterio import features, plot\n","from rasterio.plot import show_hist, reshape_as_raster, reshape_as_image\n","from rasterio.warp import calculate_default_transform, reproject, Resampling\n","from rasterstats import zonal_stats\n","import skimage.io as io\n","from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n","import joblib\n","import shutil\n","import sys\n","\n","# make sure that this path points to the location of the pygge module on your Google Drive\n","libdir = '/content/drive/MyDrive/practicals21-22' # this is where pygge.py needs to be saved\n","if libdir not in sys.path:\n","    sys.path.append(libdir)\n","\n","# import the pygge module\n","import pygge\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Week 1: Introduction to Python\n","\n","Functions, Control Flow, Lists, Loops and Strings\n","\n","Google Drive, iPython notebooks, Google Colab\n"],"metadata":{"id":"xvL1wf3U_FFA"}},{"cell_type":"markdown","source":["#Week 2: Principles of Image Data\n","\n","Data types and type conversions, data input and output\n","\n","Modules, dictionaries, files, classes and function arguments\n","\n","NumPy\n"],"metadata":{"id":"JKDrMc6uYyih"}},{"cell_type":"markdown","source":["#Week 3: Getting started with raster data processing with RasterIO\n","\n","Raster datasets and their attributes\n","\n","Coordinate reference systems\n","\n","Reading and writing image data\n","\n","Image metadata\n","\n","GDAL and RasterIO libraries"],"metadata":{"id":"72-tP4GjZIqa"}},{"cell_type":"markdown","source":["#Week 4: Image analysis and visualisation with RasterIO\n","\n","Reprojecting (warping) and reshaping a Sentinel-2 image\n","\n","Image visualisation with Matplotlib, displaying RGB channels with image band data, image enhancement\n","\n","\n"],"metadata":{"id":"r3CaM8t3Zovz"}},{"cell_type":"markdown","source":["#Week 5: Processing Sentinel-2 Image Composites\n","\n","Searching for and downloading Sentinel-2 image composites from Google Earth Engine via the Python API\n","\n","Creating an animated movie from a time series of images\n"],"metadata":{"id":"Svb3Mi05aFdC"}},{"cell_type":"markdown","source":["#Week 6: Normalised Difference Vegetation Index (NDVI) Time-Series Analysis\n","\n","Downloading time-series of Sentinel-2 reflectance for selected locations\n","\n","Calculating NDVI\n","\n","Visualisation and plotting\n"],"metadata":{"id":"lcXxYWbcahUT"}},{"cell_type":"markdown","source":["#Week 7: Accessing Sentinel-2 Images from the Copernicus Open Access Hub\n","\n","Searching for and downloading Sentinel-2 data from the Copernicus Open Access Hub API using the SentinelSat library\n","\n","Sentinel-2 file and directory structure\n","\n","Image pre-processing, including unzipping, warping and region clipping\n"],"metadata":{"id":"ON6wLvyOa4g5"}},{"cell_type":"markdown","source":["#Week 8: Vegetation Index analysis with Zonal Statistics of Polygons\n","\n","Calculating an NDVI image from Sentinel-2 image bands\n","\n","Zonal statistics: Extracting statistics of pixel values within polygons of a shapefile\n"],"metadata":{"id":"ULam9gpybX9C"}},{"cell_type":"markdown","source":["#Week 9: Machine Learning Applications\n","\n","Using QGIS to collect classification training data in a polygon vector layer\n","\n","Land cover classification and model training with random forests using the SciKit-Learn library\n","\n"],"metadata":{"id":"XTBtkSJsb0tq"}},{"cell_type":"markdown","source":["# -----------------------------"],"metadata":{"id":"FnIeYP_h_DBA"}},{"cell_type":"markdown","metadata":{"id":"qw0EK7xK_22r"},"source":["Make sure that all your files are in the right places before running the next cell.\n","\n","Edit the directory paths if they are not fitting to your own directory organisation."]},{"cell_type":"code","metadata":{"id":"hQRCnfGZrKde"},"source":["# set up your working directory with the satellite data\n","root = '/content/drive/MyDrive/practicals21-22' \n","wd = join(root, 'rf')\n","\n","# path to your download directory that contains several full Sentinel-2 images (granules)\n","s2path = join(root,'download')\n","\n","# path to our shapefile to get the extent of the clipped image area\n","shapefile = join(root, 'oakham', 'Polygons_small.shp') # ESRI Shapefile of the study area\n","\n","# names of bands to be included in the merged GeoTiff file\n","bandnames = [\"B02\", \"B03\", \"B04\", \"B08\"]\n","\n","'''\n","* We call the merged raster output file 'S2_stack.tif' because it contains several bands\n","  from several images acquired at different dates\n","'''\n","# path to the new merged file with the selected bands from different acquisition dates in GeoTiff format\n","s2merged = join(wd, 'S2_stack.tif')\n","\n","# make a filename for the classified map\n","outfile = join(wd, \"LandCoverMap.tif\")\n","\n","# define the name of the shapefile containing the training polygons\n","trainshapefile = join(wd, 'training_areas.shp')\n","\n","# define the name of the output raster file that will contain the class numbers of our\n","#   training areas as pixel values\n","trainraster = join(wd, 'training_areas.tif')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L9JjtWBU8c8S"},"source":["# Merge all bands into a single file\n","The Sentinel-2 image bands are all in separate .jp2 files. First, we need to find the file names of all image bands we want to include in the classification and merge the band rasters into a single GeoTiff file."]},{"cell_type":"code","metadata":{"id":"0Fm_Av5gPOCh"},"source":["'''\n","* We want to use all four 10 m resolution bands from all Sentinel-2 images in the download directory\n","* We stack all the band rasters into one array\n","* Use s2path pointing to the download directory (like two weeks ago)\n","'''\n","\n","# how many .SAFE directories are in the download directory?\n","# get the list of all directories in the download directory\n","dirlist = [d for d in listdir(s2path) if isdir(join(s2path, d))]\n","\n","# make an empty list of all Sentinel-2 granule IDs we have downloaded\n","s2IDs = [] \n","\n","# iterate over all Sentinel-2 .SAFE image directories\n","for d in range(len(dirlist)):\n","  # the directory names have the following structure, for example:\n","  # S2A_MSIL2A_20190919T110721_N0213_R137_T30UXD_20190919T140654.SAFE\n","  # the first part of the directory name is the granule ID\n","  # so we split off the \".SAFE\" as follows:\n","  sceneID = dirlist[d].split(\".\")[0] \n","  s2IDs.append(sceneID) #append the unique identifier to the list\n","\n","print(len(s2IDs), \" Sentinel-2 images found.\")\n","print(\"List of all Granule IDs:\")\n","pprint(s2IDs)\n","\n","# make an empty list of all band file names for all images we want to merge into one raster for the classification\n","files_selected = []\n","\n","# iterate over all Sentinel-2 image directories again\n","for d in range(len(dirlist)):\n","\n","  # get all file names of the 10 m resolution band files from all Sentinel-2 images\n","  files_10m = sorted(pygge.get_filenames(s2path, \"_10m\", \"10m\"))\n","  print(\"All bands in the image directory:\")\n","  pprint(files_10m)\n","  print(\"\\n\")\n","\n","  # We split the filename into components based on the underscore _\n","  # e.g. \"T30UXD_20190919T110721_B04_10m.jp2\"\n","  # becomes [\"T30UXD\", \"20190919T110721\", \"B04\", \"10m.jp2\"]\n","  # so the component indexed 2 contains the band number\n","  for b in bandnames:\n","    '''\n","    below, we join the directory path to the 10 m resolution imagery for the Sentinel-2\n","    granule we are just iterating over to the names of the 10 m band files,\n","    so we can later find them again\n","    '''\n","    files_selected.append([files_10m[index] for index, content in enumerate(files_10m) if b in content][0])\n","\n","print(\"\\nList of all selected band files from all acquisition dates for merging into one raster file:\")\n","for i in files_selected:\n","  print(i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZ-eA4lcaLfd"},"source":["In the cell below, we now iterate over all band files from several images acquired on different dates and write them to subsequent output bands in the merged file. For example, if 4 bands are included from each image acquisition, then the first band of the second image would become output band 4+1=5.\n","That means our output raster file needs 'bands * images' output bands. \n","We substitute len(bandnames) with len(files_selected) to create enough output bands."]},{"cell_type":"code","metadata":{"id":"3QCiq5zNaJvx"},"source":["print(\"Creating clipped, merged band file:\" + s2merged)\n","\n","# Get the shapefile layer's extent\n","extent, crs, epsg = pygge.get_shp_extent(shapefile)\n","\n","# now iterate over all band files we want to include in the merged file\n","for index, f in enumerate(files_selected):\n","\n","  with rasterio.open(f, 'r') as thisfile:\n","    # clip the input file\n","    clipfile = f.split(\".\")[0] + \"_clip.tif\"\n","    print(\"Creating temporary clipped image file: \" + clipfile)\n","    pygge.easy_clip(f, clipfile, extent)\n","    \n","    # in the first iteration, open the new file with the clipped, merged band data for write access\n","    if index == 0:\n","      # open one of the band files to get metadata\n","      bandfile = rasterio.open(clipfile, 'r')\n","      dt = bandfile.read(1).dtype\n","      # open the output file\n","      s2merged_file = rasterio.open(s2merged, 'w', driver='Gtiff', width=bandfile.width, \n","                                    height=bandfile.height, count=len(files_selected), \n","                                    crs=bandfile.crs, transform=bandfile.transform, dtype=dt)\n","      # close the file containing the metadata we copied\n","      bandfile.close()\n","\n","    # now write the clipped raster band from the input file to the output file\n","    with rasterio.open(clipfile, 'r') as bandfile:\n","      print(\"Writing clipped raster to band: \" + str(index + 1))\n","      s2merged_file.write(bandfile.read(1), index + 1)\n","    \n","    # close the clipped input raster file\n","    bandfile.close()\n","    # remove the temporary clipped input raster file\n","    os.remove(clipfile)\n","  \n","  # close the full input raster file\n","  thisfile.close()\n","\n","# close the output file\n","s2merged_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Warp the stacked file\n","\n","Now we will reproject (warp) the stacked raster file to the same projection as our shapefile or geojson file.\n"],"metadata":{"id":"oONNGpzsrxAT"}},{"cell_type":"code","metadata":{"id":"Hqo2kXFSAZG-"},"source":["# make a file name for our new file\n","warpfile = s2merged.split(sep='.')[0] + '_warped.tif'\n","\n","# warp the raster file to the same projection as the shapefile\n","pygge.easy_warp(s2merged, warpfile, epsg)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQuCnjnPTB2i"},"source":["# Visualise our image\n","At this point, we may want to check whether all processing steps have worked. We need to look at our image to see whether anything went wrong."]},{"cell_type":"code","metadata":{"id":"cK9ttYxOKQIt"},"source":["# create a figure with subplots\n","fig, ax = plt.subplots(figsize=(10,10))\n","fig.patch.set_facecolor('white')\n","\n","'''\n","We use the pygge easy_plot function here to check whether our images taken on \n","different dates are coregistered well, i.e. the pixels are in the same place.\n","Hence, we select three bands that correspond to different acquisition dates\n","but have the same wavelength.\n","'''\n","\n","# plot the bands acquired on the first, second and third acquisition date\n","#    as red, green and blue on screen\n","# The number of timesteps is the number of band files divided by the number of bands per image acquisition\n","ntimes = round(len(files_selected)/len(bandnames))\n","if ntimes == 1:\n","  timesteps=[3, 2, 1] # if only one timestep is used, then use three bands from that image\n","if ntimes == 2:\n","  timesteps=[1, 1 + len(bandnames), 1 + len(bandnames)] # if only two timesteps are\n","      # used, then use red as timestep one and green and blue as timestep two \n","if ntimes > 2:\n","  timesteps = [1, 1 + len(bandnames), 1 + len(bandnames) * 2] # else, display the \n","      # first three timesteps\n","\n","print(\"Image acquisition timesteps found: \"+str(ntimes))\n","\n","pygge.easy_plot(warpfile, ax=ax, bands = timesteps, percentiles=[0,98])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ovAPduTNKJI"},"source":["You will notice that the colour scheme looks really odd and a bit psychedelic. This is because we display bands of the same wavelength but acquired on a different date as red, green and blue channels on screen. Check out the last block of code to see how this is done."]},{"cell_type":"markdown","metadata":{"id":"frx3_iqqTGV2"},"source":["# Training a random forest model with QGIS and SciKit-Learn\n","\n","Now we will train a random forest model with all available input bands in the warped and stacked raster - there will be all selected bands from all available acquisition dates. For example, if we selected 4 bands from each downloaded image, and we downloaded 3 Sentinel-2 images acquired at different dates, then that makes 3*4=12 bands in the stacked raster file.\n","\n","The land cover classification scheme uses the following classes, which I defined when I collected the training vectors in QGIS.\n","\n","LandCover:\n","\n","1 = Water\n","\n","2 = Residential\n","\n","3 = Industrial\n","\n","4 = Pasture\n","\n","5 = Crops\n","\n","6 = Bare soil\n","\n","7 = Forest\n"]},{"cell_type":"markdown","metadata":{"id":"BWlmuIiSJ_Z4"},"source":["# Read in the shapefile with the training polygons\n","\n","In pygge, there is a function that reads in the shapefile with the training data as collected in QGIS and rasterises them to the same image extent as the image file that we will classify.\n"]},{"cell_type":"code","metadata":{"id":"6QmkXqmwvXpa"},"source":["pygge.training_shapefile_to_raster(trainshapefile, warpfile, trainraster)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7bpgFStSrKdj"},"source":["# Train the random forest model\n","\n","Now we will train the model with the rasterised training layer and the warped and stacked raster file of Sentinel-2 data. We will choose 61 decision trees in the random forest model, but this can be modified. The script saves the model to a pickle file, so we can re-use it later."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"oeRP3FqrrKdk"},"source":["# the name of our model file we want to save\n","modelfile = join(wd,\"model.pkl\")\n","\n","print(\"Input files to the random forest model training:\")\n","print(warpfile)\n","print(trainraster)\n","print(modelfile)\n","\n","# call the training function\n","model = pygge.train_rf_model(warpfile, trainraster, modelfile=modelfile, ntrees=61)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uWyxFbmUrKdl"},"source":["So far, we have fitted the random forest classification model, assessed which Sentinel-2 bands contribute most to the classification, and looked at how the number of decision trees in the random forest influences the OOB error rate. This is useful to know to see whether the number of trees selected was too low, i.e. the error still decreases a lot when more trees are added.\n"]},{"cell_type":"markdown","metadata":{"id":"97mDdqiW45vc"},"source":["#Run the classification\n","\n","The next step is to classify the Sentinel-2 image. Following the same approach as above, we define a function to do the classification, then we execute it."]},{"cell_type":"code","metadata":{"id":"HtdEoBpyrjj1"},"source":["# call our classification function\n","pygge.classify_rf(warpfile, modelfile, outfile)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8i6_HOVG9ToJ"},"source":["# Visualise the classified image\n","We need to check the results to make sure it worked. Let's take a look.\n","\n","What we do differently here is that we visualise a classified raster dataset. This means we can define our own class labels (that match our training data labels) and associate them with a colour scheme.\n"]},{"cell_type":"code","metadata":{"id":"aH0PejD99Y0h"},"source":["# inspired by https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/classify-plot-raster-data-in-python/\n","\n","# Create a list of labels to use for your legend\n","class_labels = [\"Water\", \n","                \"Residential\", \n","                \"Industrial\", \n","                \"Pasture\", \n","                \"Crops\", \n","                \"Bare soil\", \n","                \"Forest\"]\n","\n","# Create a colormap from a list of colours\n","# see this chart for information on available colours:\n","# https://matplotlib.org/2.0.0/examples/color/named_colors.html \n","colours = ['mediumblue', \n","          'firebrick', \n","          'red', \n","          'yellowgreen', \n","          'gold', \n","          'saddlebrown', \n","          'green']\n","\n","\n","# Plot our classified land cover raster\n","fig, ax = plt.subplots(figsize=(20, 10))\n","fig.patch.set_facecolor('white')\n","\n","pygge.easy_plot_landcovermap(outfile, ax, shapefile=None, band=1, xlim=None, ylim=None,\n","                           labels=class_labels, colours=colours, verbose=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wp_uvsIr5dNz"},"source":["We have produced a new land cover map from multi-temporal imagery. We could now evaluate which map is more accurate using accuracy assessment techniques.\n","\n","The classification methodology and the workflow in these practicals can be a basis for your own satellite image processing application."]},{"cell_type":"markdown","source":["# Formative assignment of the week\n","\n","Your assignment for this week is to:\n","1. Use QGIS to collect training data in a vector later with polygons. See the \n","tutorial on Blackboard / Panopto how to do this.\n","2. Download 3-10 Sentinel-2 images for your test area from different acquisition dates.\n","3. Train a random forest model.\n","4. Apply the model to the Sentinel-2 data."],"metadata":{"id":"vNYzzHlb5MEu"}},{"cell_type":"code","source":[""],"metadata":{"id":"-hcoy3IB5Ltf"},"execution_count":null,"outputs":[]}]}