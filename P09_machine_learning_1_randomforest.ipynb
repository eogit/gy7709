{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classification\n",
    "\n",
    "A random forest is a machine learning method for classification or regression. This is in a nutshell how it works:\n",
    "* Many (hundreds or thousands) decision trees are fitted to the training data. Each tree only uses a random subset of the features (e.g. spectral bands).\n",
    "* In a classification, for each pixel or object, the mode (most frequent value) of the classes is calculated over all individual trees. This is like a majority vote.\n",
    "* In a regression, for each pixel or object, the mean prediction is calculated over all individual trees.\n",
    "\n",
    "The file training_lc_Leicester.Geojson in the practicals folder has training areas (polygons) with the following land cover classes:\n",
    "\n",
    "LandCover:\n",
    "\n",
    "1 = Water\n",
    "\n",
    "2 = Residential\n",
    "\n",
    "3 = Industrial\n",
    "\n",
    "4 = Pasture\n",
    "\n",
    "5 = Crops\n",
    "\n",
    "6 = Bare soil\n",
    "\n",
    "7 = Forest\n",
    "\n",
    "\n",
    "First, we import all packages we need and define our directory structure. You can create subdirectories for the image data, training data, model output and classified maps if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: http://remote-sensing.eu/image-classification-with-python/\n",
    "\n",
    "# import all required Python packages:\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from os.path import join\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up your directories with the satellite data\n",
    "rootdir = join(os.sep, \"gy7709\", \"practicals\", \"p09\")\n",
    "# path to your training data\n",
    "path_pix = rootdir\n",
    "# path to your model\n",
    "path_model = rootdir\n",
    "# path to your classification results\n",
    "path_class = rootdir\n",
    "\n",
    "# path to your Sentinel-2 TIFF file (here we use a clipped tiff file for faster processing)\n",
    "raster = join(rootdir, \"s2a_leicester_clipped.tif\")\n",
    "# path to your corresponding pixel samples (training data converted to a geotiff raster file)\n",
    "# pixel values are the class numbers\n",
    "samples = join(path_pix, \"training_raster.tif\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we first define a function to read in the raster file with our training data. Each pixel value represents the class of that pixel. This file was created in QGIS with the Vector to Raster conversion tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a new function\n",
    "def training(raster, samples, ntrees = 201):\n",
    "    '''\n",
    "    raster = filename and path to the raster file to be classified (in tiff format)\n",
    "    samples = filename and path to the raster file with the training samples as pixel values (in tiff format)\n",
    "    ntrees = number of trees in the random forest\n",
    "    '''\n",
    "    # read in clipped Sentinel-2A raster from geotiff (unsigned 16-bit integer format)\n",
    "    # this was created in QGIS from the original Sentinel-2 10m bands (R,G,B,NIR)\n",
    "    img_ds = io.imread(raster)\n",
    "    # convert to 16bit numpy array \n",
    "    img = np.array(img_ds, dtype='int16')\n",
    "\n",
    "    # do the same with your training sample pixels \n",
    "    roi_ds = io.imread(samples)   \n",
    "    roi = np.array(roi_ds, dtype='int8')  \n",
    "    \n",
    "    # read in your labels\n",
    "    labels = np.unique(roi[roi > 0]) \n",
    "    print('The training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
    "\n",
    "    # compose your X,Y data (dataset - training data)     \n",
    "    # 0 = missing value\n",
    "    X = img[roi > 0, :] \n",
    "    Y = roi[roi > 0]     \n",
    "\n",
    "    # assign class weights (class 1 has the weight 1, etc.)\n",
    "    weights = {1:1, 2:2, 3:2, 4:1, 5:2, 6:2, 7:2}\n",
    "\n",
    "    # build your Random Forest Classifier \n",
    "    # for more information: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "    rf = RandomForestClassifier(class_weight = weights, n_estimators = ntrees, criterion = 'gini', max_depth = 4, \n",
    "                                min_samples_split = 2, min_samples_leaf = 1, max_features = 'auto', \n",
    "                                bootstrap = True, oob_score = True, n_jobs = 1, random_state = None, verbose = True)  \n",
    "\n",
    "    # alternatively you may try out a Gradient Boosting Classifier \n",
    "    # It is much less RAM consuming and considers weak training data      \n",
    "    \"\"\" \n",
    "    rf = GradientBoostingClassifier(n_estimators = ntrees, min_samples_leaf = 1, min_samples_split = 4, max_depth = 4,    \n",
    "                                    max_features = 'auto', learning_rate = 0.8, subsample = 1, random_state = None,         \n",
    "                                    warm_start = True)\n",
    "    \"\"\"\n",
    "\n",
    "    # now fit your training data with the original dataset\n",
    "    rf = rf.fit(X,Y)\n",
    "\n",
    "    # export your Random Forest / Gradient Boosting Model     \n",
    "    model = join(path_model, \"model.pkl\")\n",
    "    joblib.dump(rf, model)\n",
    "    \n",
    "    # calculate feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    # Out-of-bag error rate as a function of number of trees:\n",
    "    oob_error = [] # define an empty list with pairs of values\n",
    "    \n",
    "    # Range of `n_estimators` values to explore.\n",
    "    mintrees = 50 # this needs to be a sensible minimum number to get reliable OOB error estimates\n",
    "    maxtrees = max(mintrees, ntrees) # go all the way to the highest number of trees\n",
    "    nsteps = 40 # number of steps to calculate OOB error rate for (saves time)\n",
    "    \n",
    "    # work out error rate for each number of trees in the random forest\n",
    "    for i in range(mintrees, maxtrees + 1, round((maxtrees - mintrees)/nsteps)): # start, end, step\n",
    "        rf.set_params(n_estimators=i)\n",
    "        rf.fit(X, Y)\n",
    "        oob_error.append((i, 1 - rf.oob_score_))\n",
    "\n",
    "    # Plot OOB error rate vs. number of trees\n",
    "    xs, ys = zip(*oob_error)\n",
    "    plt.plot(xs, ys)\n",
    "    plt.xlim(0, maxtrees)\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"OOB error rate\")\n",
    "    #    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us execute the function we have just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelfile = training(raster, samples, ntrees=501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have fitted the random forest classification model, assessed which Sentinel-2 bands contribute most to the classification, and looked at how the number of decision trees in the random forest influences the OOB error rate. This is useful to know to see whether the number of trees selected was too low, i.e. the error still decreases a lot when more trees are added.\n",
    "\n",
    "The next step is to classify the whole Sentinel-2 image extent. Following the same approach as above, we define a function to do the classification, then we execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(raster, model):\n",
    "    '''\n",
    "    raster = filename and path to the raster file to be classified (in tiff format)\n",
    "    model = filename and path to the pickled file with the random forest model\n",
    "    '''\n",
    "\n",
    "    # Read Data    \n",
    "    img_ds = io.imread(raster)   \n",
    "    img = np.array(img_ds, dtype='int16')    \n",
    "\n",
    "    # call your random forest model\n",
    "    clf = joblib.load(model)    \n",
    "\n",
    "    # Classification of array and save as image (5 refers to the number of bands)\n",
    "    new_shape = (img.shape[0] * img.shape[1], img.shape[2]) \n",
    "    img_as_array = img[:, :, :5].reshape(new_shape)   \n",
    "\n",
    "    class_prediction = clf.predict(img_as_array) \n",
    "    class_prediction = class_prediction.reshape(img[:, :, 0].shape)  \n",
    "\n",
    "    # now export your classification\n",
    "    classification = join(path_class, \"landcover_randomforest.tif\") \n",
    "    io.imsave(classification, class_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the classification function and see what output we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification(raster, modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your portfolio assignment\n",
    "First, after running the code above, re-run the random forest model twice:\n",
    "a) with fewer decision trees\n",
    "b) with more decision trees\n",
    "Both times, save the outputs under different filenames.\n",
    "\n",
    "Take screenshots of the different Random Forest outputs and add them to your portfolio. Write down the reasons for choosing that number of trees in your portfolio.\n",
    "Add the diagnostic statistics and graphs for both runs.\n",
    "Show the classified output maps for a selected area of interest and write about 300 words describing the similarities and differences between the two maps.\n",
    "Identify some interesting features in the maps. You can use arrows to annotate the maps.\n",
    "\n",
    "As a second assignment, modify the classification function such that it returns the name and directory path of the output file. Copy the new function into your portfolio and explain how you did it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
