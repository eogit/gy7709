{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "practical_sync_week10_Multitemporal_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUexW0CmhlF3"
      },
      "source": [
        "# Week 10: Classifying multitemporal image stacks\n",
        "\n",
        "Individual learning outcomes: After this week, all students should be able to stack multi-temporal Sentinel-2 images into a raster stack (e.g. spring and autumn images), train a random forest model with the stack of images and run the classification on that stack.\n",
        "\n",
        "All we need to do is modify the iPython notebook from last week. We classified a single Sentinel-2 image using a random forest classification. We trained the model with a raster layer which contains class numbers as pixel values.\n",
        "\n",
        "This week, we use the same training raster. We will, however, train the model on a raster that contains reflectance bands from several Sentinel-2 images acquired on different dates, and then classify that stack of images into a single map."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "___N_2vyp_f2"
      },
      "source": [
        "First, we need to connect to our Google Drive from Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RvpK17wXp_f7"
      },
      "source": [
        "# Load the Drive helper and mount your Google Drive as a drive in the virtual machine\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxAdkqX7_ZZw"
      },
      "source": [
        "Now let us import all necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXnzg_pcTSEP"
      },
      "source": [
        "# Adapted from: http://remote-sensing.eu/image-classification-with-python/\n",
        "\n",
        "#import required libraries\n",
        "!pip install rasterio\n",
        "!pip install sentinelsat\n",
        "!pip install geopandas\n",
        "!pip install rasterio\n",
        "!pip install rasterstats\n",
        "import csv \n",
        "import geopandas as gpd\n",
        "import math\n",
        "from math import floor, ceil\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ogr\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "from osgeo import gdal\n",
        "import pickle\n",
        "from pyproj import Proj\n",
        "from pprint import pprint\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from rasterio import features, plot\n",
        "from rasterio.plot import show_hist, reshape_as_raster, reshape_as_image\n",
        "from rasterstats import zonal_stats\n",
        "import skimage.io as io\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.externals import joblib\n",
        "import shutil\n",
        "import sys\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw0EK7xK_22r"
      },
      "source": [
        "Make sure that all your files are in the right places before running the next cell.\n",
        "\n",
        "Edit the directory paths if they are not fitting to your own directory organisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQRCnfGZrKde"
      },
      "source": [
        "# set up your working directory with the satellite data\n",
        "wd = '/content/drive/MyDrive/practicals20-21/rf'\n",
        "\n",
        "'''\n",
        "modified from last week:\n",
        "* s2path now points to a directory of several images (.SAFE directories)\n",
        "  rather than a single Sentinel-2 image (we called this 'downloaddir' previously)\n",
        "'''\n",
        "# path to your download directory that contains several full Sentinel-2 images (granules)\n",
        "s2path = '/content/drive/MyDrive/practicals20-21/download/'\n",
        "\n",
        "# path to our shapefile to get the extent of the clipped image area\n",
        "shapefile = join('/content/drive/MyDrive/practicals20-21', 'oakham', 'Polygons_small.shp') # ESRI Shapefile of the study area\n",
        "\n",
        "# names of bands to be included in the merged GeoTiff file\n",
        "bandnames = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
        "\n",
        "'''\n",
        "modified from last week:\n",
        "* We call the merged raster file S2_stack.tif now because it contains several bands\n",
        "  from several images acquired at different dates\n",
        "'''\n",
        "# path to the new merged file with the selected bands in GeoTiff format\n",
        "s2merged = '/content/drive/MyDrive/practicals20-21/rf/S2_stack.tif'\n",
        "\n",
        "# path to your corresponding pixel samples (training data converted to a geotiff raster file)\n",
        "# pixel values are the class numbers\n",
        "#samples = join(wd, \"training_raster.tif\") \n",
        "\n",
        "'''\n",
        "modified from last week:\n",
        "* We use a different output file name to avoid overwriting the file from last week\n",
        "'''\n",
        "# make a filename for the classified map\n",
        "outfile = join(wd, \"LandCoverMap_multitemp.tif\")\n",
        "\n",
        "# define the name of the shapefile containing the training polygons\n",
        "trainshapefile = '/content/drive/MyDrive/practicals20-21/rf/training_areas.shp'\n",
        "\n",
        "# define the name of the output raster file that will contain the class numbers of our\n",
        "#   training areas as pixel values\n",
        "trainraster = '/content/drive/MyDrive/practicals20-21/rf/training_areas.tif'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpoPwvQy8YML"
      },
      "source": [
        "We define the same helper function as last week to convert coordinates for the clipping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gceBeSJI7pKF"
      },
      "source": [
        "# define a helper function that converts latitude, longitude coordinates into pixel locations\n",
        "def longlat2window(lon, lat, dataset):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        lon (tuple): Tuple of min and max lon\n",
        "        lat (tuple): Tuple of min and max lat\n",
        "        dataset: Rasterio dataset\n",
        "\n",
        "    Returns:\n",
        "        rasterio.windows.Window\n",
        "    \"\"\"\n",
        "    p = Proj(dataset.crs)\n",
        "    t = dataset.transform\n",
        "    xmin, ymin = p(lon[0], lat[0])\n",
        "    xmax, ymax = p(lon[1], lat[1])\n",
        "    col_min, row_min = ~t * (xmin, ymin)\n",
        "    col_max, row_max = ~t * (xmax, ymax)\n",
        "    return Window.from_slices(rows=(floor(row_max), ceil(row_min)),\n",
        "                              cols=(floor(col_min), ceil(col_max)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9JjtWBU8c8S"
      },
      "source": [
        "# Merge all bands into a single file\n",
        "The Sentinel-2 image bands are all in separate .jp2 files. First, we need to find the file names of all image bands we want to include in the classification and merge the band rasters into a single GeoTiff file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fm_Av5gPOCh"
      },
      "source": [
        "'''\n",
        "Changed from last week:\n",
        "* Use all four 10 m resolution bands from all Sentinel-2 images in the download directory\n",
        "* Use s2path pointing to the download directory (like two weeks ago)\n",
        "'''\n",
        "\n",
        "# how many .SAFE directories are in the download directory?\n",
        "# get the list of all directories in the download directory\n",
        "dirlist = [d for d in listdir(s2path) if isdir(join(s2path, d))]\n",
        "\n",
        "# make an empty list of all Sentinel-2 granule IDs we have downloaded\n",
        "s2IDs = [] \n",
        "\n",
        "# iterate over all Sentinel-2 .SAFE image directories\n",
        "for d in range(len(dirlist)):\n",
        "  # the directory names have the following structure, for example:\n",
        "  # S2A_MSIL2A_20190919T110721_N0213_R137_T30UXD_20190919T140654.SAFE\n",
        "  # the first part of the directory name is the granule ID\n",
        "  # so we split off the \".SAFE\" as follows:\n",
        "  sceneID = dirlist[d].split(\".\")[0] \n",
        "  s2IDs.append(sceneID) #append the unique identifier to the list\n",
        "\n",
        "print(len(s2IDs), \" Sentinel-2 images found.\")\n",
        "print(\"List of all Granule IDs:\")\n",
        "pprint(s2IDs)\n",
        "\n",
        "# make an empty list of all directory paths pointing to the selected 10 m resolution band files\n",
        "s2dirs = [] \n",
        "\n",
        "# make an empty list of all band file names for all images we want to merge into oe raster for the classification\n",
        "files_selected = []\n",
        "\n",
        "# iterate over all Sentinel-2 image directories again\n",
        "for d in range(len(dirlist)):\n",
        "  # the directory names have the following structure, for example:\n",
        "  # S2A_MSIL2A_20190919T110721_N0213_R137_T30UXD_20190919T140654.SAFE\n",
        "  # the first part of the directory name is the granule ID\n",
        "  # so we split off the \".SAFE\" as follows:\n",
        "  sceneID = dirlist[d].split(\".\")[0] \n",
        "  s2IDs.append(sceneID) #append the unique identifier to the list\n",
        "\n",
        "  # find the GRANULE, then L2A_*, then IMG_DATA, then R10m directory\n",
        "  thisdir = join(s2path, dirlist[d], \"GRANULE\")\n",
        "\n",
        "  # find the full name of the L2A_* subdirectory (contains the scene ID)\n",
        "  subdirlist = [s for s in listdir(thisdir) if isdir(join(thisdir, s))]\n",
        "  for y in range(len(subdirlist)):\n",
        "    if subdirlist[y].split(\"_\")[0] == \"L2A\":\n",
        "      thisdir = join(thisdir, subdirlist[y])\n",
        "\n",
        "  # add IMG_DATA/R10m to subdirectory, this is where the TCI image is found\n",
        "  s2dir = join(thisdir, \"IMG_DATA\", \"R10m\")\n",
        "  s2dirs.append(s2dir) # add it to our list\n",
        "\n",
        "  # get all image band file names\n",
        "  files_10m = [f for f in listdir(s2dir) if isfile(join(s2dir, f))]\n",
        "  files_10m = sorted(files_10m)\n",
        "\n",
        "  print(\"All bands in the image directories:\")\n",
        "  pprint(files_10m)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  # We split the filename into components based on the underscore _\n",
        "  # e.g. \"T30UXD_20190919T110721_B04_10m.jp2\"\n",
        "  # becomes [\"T30UXD\", \"20190919T110721\", \"B04\", \"10m.jp2\"]\n",
        "  # so the component indexed 2 contains the band number\n",
        "  for b in bandnames:\n",
        "    '''\n",
        "    changed from last week:\n",
        "    * below, we join the directory path to the 10 m resolution imagery for the Sentinel-2\n",
        "      granule we are just iterating over to the names of the 10 m band files,\n",
        "      so we can later find them again\n",
        "    '''\n",
        "    files_selected.append([join(s2dir, files_10m[index]) for index, content in enumerate(files_10m) if b in content][0])\n",
        "\n",
        "print(\"List of all Sentinel-2 directories:\")\n",
        "for i in s2dirs:\n",
        "  print(i)\n",
        "print(\"\\nList of all selected band image files for merging into one raster file:\")\n",
        "for i in files_selected:\n",
        "  print(i)\n",
        "\n",
        "# open one of the band files to get metadata\n",
        "f = rasterio.open(join(s2dir, files_selected[0]))\n",
        "dt = f.read(1).dtype\n",
        "\n",
        "'''\n",
        "changed from last week:\n",
        "* below, we now have to iterate over all band files from several images acquired on different dates\n",
        "  and write them to subsequent output bands in the merged file, e.g. if 4 bands are \n",
        "  included from each image, then the first band of the second image would become output band 5.\n",
        "  That means our output raster file needs 'bands * images' output bands.\n",
        "  We substitute len(bandnames) with len(files_selected) to create enough output bands.\n",
        "'''\n",
        "\n",
        "# open the new file with the merged band data for writing\n",
        "s2merged_file = rasterio.open(s2merged, 'w', driver='Gtiff', width=f.width, \n",
        "                              height=f.height, count=len(files_selected), \n",
        "                              crs=f.crs, transform=f.transform, dtype=dt)\n",
        "\n",
        "# close the file\n",
        "f.close()\n",
        "\n",
        "'''\n",
        "changed from last week:\n",
        "* files_selected this time includes the full directory path, so we do not need to\n",
        "  merge the directory name with the file name anymore\n",
        "'''\n",
        "\n",
        "# now iterate over all band files we want to include in the merged file\n",
        "for index, f in enumerate(files_selected):\n",
        "  with rasterio.open(f, 'r') as thisfile:\n",
        "    s2merged_file.write(thisfile.read(1), index+1)\n",
        "  # close the file\n",
        "  thisfile.close()\n",
        "\n",
        "# close the output file\n",
        "s2merged_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dyA_FD-SHzU"
      },
      "source": [
        "# Warp the merged raster file\n",
        "Because we want to display the results together with our shapefile, we need to warp the raster data, as we did before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyDGBbbZRW0z"
      },
      "source": [
        "# warp it to the same projection as the shapefile\n",
        "\n",
        "# get the shapefile extent\n",
        "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
        "ds = driver.Open(shapefile, 0)\n",
        "lyr = ds.GetLayer()\n",
        "extent = lyr.GetExtent()\n",
        "print(\"Extent of the area of interest (shapefile):\\n\", extent)\n",
        "\n",
        "# get projection information of the shapefile\n",
        "outSpatialRef = lyr.GetSpatialRef().ExportToWkt()\n",
        "ds = None # close file\n",
        "\n",
        "print(\"Reprojecting image to the following projection:\")\n",
        "print(outSpatialRef)\n",
        "\n",
        "# make a file name for our new file\n",
        "warpfile = s2merged.split(sep='.')[0] + '_warped.tif'\n",
        "\n",
        "# check whether the warp file already exists and skip if it does\n",
        "if not os.path.exists(warpfile):\n",
        "  print(\"Creating warped file:\" + warpfile)\n",
        "  # call the GDAL Warp command\n",
        "  ds = gdal.Warp(warpfile, s2merged, dstSRS=outSpatialRef)\n",
        "  if ds == None:\n",
        "    print()\n",
        "  ds = None #remember to close and save the output file\n",
        "else:\n",
        "  print(\"warped file already exists\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aecyUyl98obK"
      },
      "source": [
        "# Clip the image file to our area of interest\n",
        "Here, we do not want to classify the entire Sentinel-2 granule (image). We only want to classify our area of interest defined by the shapefile extent.\n",
        "\n",
        "Hence we have to clip our merged, warped image to that extent. This will also speed up processing time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeHlW4hvKM2-"
      },
      "source": [
        "# clip the merged, warped file\n",
        "\n",
        "# make the filename of the new zoom image file\n",
        "clipfile = warpfile.split(\".\")[0] + \"_clip.tif\"\n",
        "print(\"Producing clipped image file: \" + clipfile)\n",
        "\n",
        "# clip it with rasterio to the shapefile extent\n",
        "# rasterio offers an option called 'window' to load a subset of a raster file\n",
        "\n",
        "# open the source file\n",
        "with rasterio.open(warpfile, 'r') as src:\n",
        "  \n",
        "  # convert the shapefile extent to a rasterio window object\n",
        "  window = longlat2window((extent[0], extent[1]), (extent[2], extent[3]), src)\n",
        "  print(\"Window coordinates: \", window)\n",
        "  \n",
        "  # read all bands but only for the window extent\n",
        "  arr = src.read(window=window, out_shape=(src.count, window.height, window.width))\n",
        "  print(\"Window array size: \", arr.shape)\n",
        "\n",
        "  # get the data type\n",
        "  dt = arr.dtype\n",
        "\n",
        "  # open the destination file\n",
        "  # copy metadata from source file\n",
        "  # BUT we must change the geotransform to the window with the update below\n",
        "  # https://rasterio.readthedocs.io/en/latest/topics/windowed-rw.html\n",
        "  kwargs = src.meta.copy()\n",
        "  kwargs.update({'height': window.height,\n",
        "                  'width': window.width,\n",
        "                  'transform': rasterio.windows.transform(window, src.transform),\n",
        "                  'driver': 'Gtiff', \n",
        "                  'count': src.count,\n",
        "                  'crs': src.crs,\n",
        "                  'dtype': dt\n",
        "                  })\n",
        "\n",
        "  with rasterio.open(clipfile, 'w', **kwargs) as dst:\n",
        "    dst.write(arr)\n",
        "\n",
        "    # close the destination file\n",
        "    dst.close()\n",
        "\n",
        "  # close the sourcefile\n",
        "  src.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQuCnjnPTB2i"
      },
      "source": [
        "# Visualise our image\n",
        "At this point, we may want to check whether all processing steps have worked. We need to look at our image to see whether anything went wrong.\n",
        "\n",
        "We define our helper function to plot a true colour image on screen, as we did before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU7a0a_ONUJQ"
      },
      "source": [
        "# We need our old helper function to convert an image to uint8 data type for plotting\n",
        "def tci(afile, ax=None, bands=[3,2,1], percentiles=[0,100], xlim=None, ylim=None): \n",
        "  # tci stands for true colour image\n",
        "  # afile is a handle to an image file opened with RasterIO.Open()\n",
        "  # ax is the axes handle to plot the map on\n",
        "  # bands is the order of image bands in the source file to become RGB channels\n",
        "  # percentiles = list of percentiles for trimming the histogram\n",
        "  #    [0,100] stands for min, max\n",
        "  # xlim =[xmin, xmax] is the map extent to be shown in x direction\n",
        "  # ylim =[ymin, ymax] is the map extent to be shown in y direction\n",
        "  \n",
        "  # we define a function within this function:\n",
        "  def scale_to_uint8(x, percentiles=[0,100]):\n",
        "    # scale array x to 0-255 and convert to uint8\n",
        "    # x = input array\n",
        "    # percentiles = list of percentiles for trimming the histogram\n",
        "    #    [0,1] stands for min, max\n",
        "    x = np.float32(x)\n",
        "    amin = np.percentile(x, percentiles[0])\n",
        "    amax = np.percentile(x, percentiles[1])\n",
        "    anewmin = 0.0\n",
        "    anewmax = 255.0\n",
        "    xscaled = (x - amin) * ((anewmax - anewmin) / (amax - amin)) + anewmin\n",
        "    return(xscaled.astype(np.uint8))\n",
        "\n",
        "  # save the uint8 image as a temporary Geotiff file\n",
        "  tmpfile = rasterio.open('tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff',\n",
        "                            'w',driver='Gtiff', width=afile.width, height=afile.height,\n",
        "                            count=3, crs=afile.crs, transform=afile.transform, \n",
        "                            dtype=np.uint8)\n",
        "\n",
        "  # mask out extreme values for each band\n",
        "  for b in range(3):\n",
        "    # read band data\n",
        "    a = afile.read(bands[b])\n",
        "    a_uint8 = scale_to_uint8(a, percentiles) \n",
        "    # write the output into the new file as band b+1\n",
        "    tmpfile.write(a_uint8, b+1)\n",
        "\n",
        "  # close the file\n",
        "  tmpfile.close()\n",
        "\n",
        "  # try plotting the image\n",
        "  imgfile = rasterio.open(r'tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff', count=3)\n",
        "\n",
        "  if (xlim==None):\n",
        "    xlim=[afile.bounds.left, afile.bounds.right]\n",
        "    # afile.bounds returns a BoundingBox(left, bottom, right, top) object,\n",
        "    #    from which we need to get the corner coordinates like so\n",
        "\n",
        "  if (ylim==None):\n",
        "    ylim=[afile.bounds.bottom, afile.bounds.top]\n",
        "  \n",
        "  # zoom in to an area of interest by setting the axes limits of our map\n",
        "  ax.set_xlim(xlim)\n",
        "  ax.set_ylim(ylim)\n",
        "  plot.show(imgfile, ax=ax)\n",
        "\n",
        "  # close the temporary file\n",
        "  imgfile.close()\n",
        "\n",
        "  # and remove the temporary file when we do not need it anymore\n",
        "  os.remove('tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff')\n",
        "\n",
        "  return()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK9ttYxOKQIt"
      },
      "source": [
        "# create a figure with subplots\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "'''\n",
        "changed from last week:\n",
        "* We use the tci plotting function here to check whether our images taken on \n",
        "  different dates are coregistered well, i.e. the pixels are in the same place.\n",
        "  Hence, we select three bands that correspond to different acquisition dates\n",
        "  but have the same wavelength.\n",
        "'''\n",
        "\n",
        "# plot it and display the blue band acquired on the first, second and third acquisition date\n",
        "#    as red, green and blue on screen\n",
        "with rasterio.open(clipfile, \"r\") as img:\n",
        "  tci(img, ax=ax, bands = [1, 1+len(bandnames), 1+2*len(bandnames)], percentiles=[0,98])\n",
        "  # set a title for the subplot\n",
        "  mytitle = clipfile\n",
        "  ax.set_title(mytitle, fontsize=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ovAPduTNKJI"
      },
      "source": [
        "You will notice that the colour scheme looks really odd and a bit psychedelic. This is because we display bands of the same wavelength but acquired on a different date as red, green and blue channels on screen. Check out the last block of code to see how this is done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frx3_iqqTGV2"
      },
      "source": [
        "# Training a random forest model with QGIS and SciKit-Learn\n",
        "\n",
        "We will do the same like last week, but this time our model will be trained on many more input bands from different acquisition dates.\n",
        "\n",
        "LandCover:\n",
        "\n",
        "1 = Water\n",
        "\n",
        "2 = Residential\n",
        "\n",
        "3 = Industrial\n",
        "\n",
        "4 = Pasture\n",
        "\n",
        "5 = Crops\n",
        "\n",
        "6 = Bare soil\n",
        "\n",
        "7 = Forest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWlmuIiSJ_Z4"
      },
      "source": [
        "# Read in the shapefile with the training polygons\n",
        "We need to read in the vector layer that contains our training areas first of all, convert it to the same coordinate reference system as our raster file and create a new training raster file with 'burned-in' pixel values showing class numbers. This function will do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEXDyhtdJfCd"
      },
      "source": [
        "def read_training_shapefile(training_shapefilename, inraster_filename, outraster_filename):\n",
        "  '''\n",
        "  This function reads in a shapefile with training polygons and produces a raster file\n",
        "     that aligns with an input rasterfile (same corner coordinates, resolution, coordinate \n",
        "     reference system and geotransform). Each pixel value in the output raster will\n",
        "     indicate the class number of the training shapefile based on the attribute column \n",
        "     named 'Class' with a capital C.\n",
        "\n",
        "  Credit: https://gis.stackexchange.com/questions/151339/rasterize-a-shapefile-with-geopandas-or-fiona-python  \n",
        "\n",
        "  Parameters:\n",
        "  training_shapefilename = string pointing to the input training shapefile in ESRI format\n",
        "  inraster_filename = string pointing to the input raster file that we want to align the output raster to\n",
        "  outraster_filename = string pointing to the output raster file\n",
        "\n",
        "  '''\n",
        "\n",
        "  # Open the shapefile with GeoPANDAS\n",
        "  shp = gpd.read_file(training_shapefilename)\n",
        "\n",
        "  # Open the input raster file with RasterIO  \n",
        "  inraster = rasterio.open(inraster_filename, 'r')\n",
        "  # Reproject the geometries from the shapefile to the CRS of the raster\n",
        "  shp = shp.to_crs(inraster.crs)\n",
        "\n",
        "  # copy and update the metadata from the input raster for the output\n",
        "  meta = inraster.meta.copy()\n",
        "  meta.update(dtype=np.uint8)\n",
        "  meta.update(count=1)\n",
        "\n",
        "  # Now burn the features into the raster and write it\n",
        "  with rasterio.open(outraster_filename, 'w', **meta) as outraster:\n",
        "    # create the output array as a Numpy array filled with zeros and of the same\n",
        "    #    shape as the input raster\n",
        "    raster_shape = inraster.read(1).shape\n",
        "    out_arr = np.zeros(raster_shape, dtype=np.uint8)\n",
        "    \n",
        "    # this is where we create a generator of geom, value pairs to use in rasterizing\n",
        "    shapes = ((geom, value) for geom, value in zip(shp.geometry, shp.Class))\n",
        "    burned = features.rasterize(shapes=shapes, fill=0, out=out_arr, \n",
        "                                transform=outraster.transform, all_touched=False)\n",
        "\n",
        "    '''\n",
        "    # uncomment this part if you want detailed printed output\n",
        "\n",
        "    print(\"Shapefile attribute table and polygon geometries:\")\n",
        "    pprint(shp)\n",
        "\n",
        "    print(\"shapes is a generator object:\")\n",
        "    print(shapes)\n",
        "\n",
        "    # this is how we can access its contents (for convenience we print the class first):\n",
        "    for geom, value in zip(shp.geometry, shp.Class):\n",
        "      print(value, geom)\n",
        "\n",
        "    print(\"Rasterised layer:\")    \n",
        "    print(burned)\n",
        "    print(\"The output raster has values from \", np.min(burned), \" to \", np.max(burned))\n",
        "    '''\n",
        "    \n",
        "    outraster.write(burned.astype(np.uint8), 1)\n",
        "    outraster = None\n",
        "  inraster = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXNBdQWlvVb9"
      },
      "source": [
        "Now run the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QmkXqmwvXpa"
      },
      "source": [
        "print(trainshapefile)\n",
        "print(clipfile)\n",
        "print(trainraster)\n",
        "\n",
        "read_training_shapefile(trainshapefile, clipfile, trainraster)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msq4f4onrKdh"
      },
      "source": [
        "# Build the random forest model\n",
        "Now we can define a function to read in the training raster file, build the random forest classification model, print some model diagnostics and save the model as a picle file for future use. Each pixel value in the training raster represents the land cover class of that pixel. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7woShvarKdh"
      },
      "source": [
        "# declare a new function\n",
        "def training(raster, samples, modelfile, ntrees = 101):\n",
        "    '''\n",
        "    raster = filename and path to the raster file to be classified (in tiff format)\n",
        "    samples = filename and path to the raster file with the training samples as pixel values (in tiff format)\n",
        "    modelfile = filename and path to a pickle file to save the trained model in\n",
        "    ntrees = number of trees in the random forest\n",
        "    '''\n",
        "    # read in clipped Sentinel-2A raster from geotiff (unsigned 16-bit integer format)\n",
        "    img_ds = io.imread(raster)\n",
        "    # convert to 16bit numpy array \n",
        "    img = np.array(img_ds, dtype='int16')\n",
        "\n",
        "    # do the same with your training sample pixels \n",
        "    roi_ds = io.imread(samples)   \n",
        "    roi = np.array(roi_ds, dtype='int8')  \n",
        "    \n",
        "    # read in your labels\n",
        "    labels = np.unique(roi[roi > 0]) \n",
        "    print('The training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
        "\n",
        "    # compose your X,Y data (dataset - training data)     \n",
        "    # 0 = missing value\n",
        "    X = img[roi > 0, :] \n",
        "    Y = roi[roi > 0]     \n",
        "\n",
        "    # assign class weights (class 1 has the weight 1, etc.)\n",
        "    weights = {1:1, 2:2, 3:2, 4:1, 5:2, 6:2, 7:2}\n",
        "\n",
        "    # build your Random Forest Classifier \n",
        "    # for more information: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "    rf = RandomForestClassifier(class_weight = weights, n_estimators = ntrees, criterion = 'gini', max_depth = 4, \n",
        "                                min_samples_split = 2, min_samples_leaf = 1, max_features = 'auto', \n",
        "                                bootstrap = True, oob_score = True, n_jobs = 1, random_state = None, verbose = True)  \n",
        "\n",
        "    # alternatively you may try out a Gradient Boosting Classifier \n",
        "    # It is much less RAM consuming and considers weak training data      \n",
        "    \"\"\" \n",
        "    rf = GradientBoostingClassifier(n_estimators = ntrees, min_samples_leaf = 1, min_samples_split = 4, max_depth = 4,    \n",
        "                                    max_features = 'auto', learning_rate = 0.8, subsample = 1, random_state = None,         \n",
        "                                    warm_start = True)\n",
        "    \"\"\"\n",
        "\n",
        "    # now fit your training data with the original dataset\n",
        "    rf = rf.fit(X,Y)\n",
        "\n",
        "    # export your Random Forest / Gradient Boosting Model     \n",
        "    joblib.dump(rf, modelfile)\n",
        "    \n",
        "    # calculate feature importances\n",
        "    importances = rf.feature_importances_\n",
        "    std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    # Print the feature ranking\n",
        "    print(\"Feature ranking:\")\n",
        "    for f in range(X.shape[1]):\n",
        "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "    # Plot the feature importances of the forest\n",
        "    plt.figure()\n",
        "    plt.title(\"Feature importances\")\n",
        "    plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
        "    plt.xticks(range(X.shape[1]), indices)\n",
        "    plt.xlim([-1, X.shape[1]])\n",
        "    plt.show()\n",
        "    \n",
        "    # Out-of-bag error rate as a function of number of trees:\n",
        "    oob_error = [] # define an empty list with pairs of values\n",
        "    \n",
        "    # Range of `n_estimators` values to explore.\n",
        "    mintrees = 50 # this needs to be a sensible minimum number to get reliable OOB error estimates\n",
        "    maxtrees = max(mintrees, ntrees) # go all the way to the highest number of trees\n",
        "    nsteps = 10 # number of steps to calculate OOB error rate for (saves time)\n",
        "    \n",
        "    # work out error rate for each number of trees in the random forest\n",
        "    for i in range(mintrees, maxtrees + 1, round((maxtrees - mintrees)/nsteps)): # start, end, step\n",
        "        rf.set_params(n_estimators=i)\n",
        "        rf.fit(X, Y)\n",
        "        oob_error.append((i, 1 - rf.oob_score_))\n",
        "\n",
        "    # Plot OOB error rate vs. number of trees\n",
        "    xs, ys = zip(*oob_error)\n",
        "    plt.plot(xs, ys)\n",
        "    # plt.xlim(0, maxtrees)\n",
        "    plt.xlabel(\"n_estimators\")\n",
        "    plt.ylabel(\"OOB error rate\")\n",
        "    # plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n",
        "    return(rf) # returns the random forest model object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bpgFStSrKdj"
      },
      "source": [
        "# Train the random forest model\n",
        "Now let us execute the function we have just defined. This will read in our merged, warped and clipped image and our training raster. From those two datasets, the random forest algorithm will define a collection of decision trees that best represent land cover as a function of spectral band information contained in the satellite image. \n",
        "\n",
        "We save that model to a pickle file for further use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "oeRP3FqrrKdk"
      },
      "source": [
        "# the name of our model file we want to save\n",
        "modelfile = wd+\"model.pkl\"\n",
        "\n",
        "print(clipfile)\n",
        "print(trainraster)\n",
        "print(modelfile)\n",
        "\n",
        "# call the training function\n",
        "model = training(clipfile, trainraster, ntrees=61, modelfile=modelfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWyxFbmUrKdl"
      },
      "source": [
        "So far, we have fitted the random forest classification model, assessed which Sentinel-2 bands contribute most to the classification, and looked at how the number of decision trees in the random forest influences the OOB error rate. This is useful to know to see whether the number of trees selected was too low, i.e. the error still decreases a lot when more trees are added.\n",
        "\n",
        "The next step is to classify the Sentinel-2 image. Following the same approach as above, we define a function to do the classification, then we execute it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6uAhzkhrjj1"
      },
      "source": [
        "# Classify the image\n",
        "Now let's run the classification function and see what output we get."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiLAmuAPTJUo"
      },
      "source": [
        "# Define our random forest classification function\n",
        "As with the training of our model, we want to define a function that applies that model to a new image raster, classifies it and saves the land cover map to an output file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0YniMeTrjjy"
      },
      "source": [
        "def classification(raster, modelfile, outfile):\n",
        "    '''\n",
        "    raster = filename and path to the raster file to be classified (in tiff uint16 format)\n",
        "    modelfile = filename and path to the pickled file with the random forest model in uint8 format\n",
        "    outfile = filename and path to the output file with the classified map in uint8 format\n",
        "    '''\n",
        "\n",
        "    # Read Data    \n",
        "    src = rasterio.open(raster, 'r')   \n",
        "    img = src.read()\n",
        "\n",
        "    print(\"img.shape = \", img.shape)\n",
        "\n",
        "    # get number of bands\n",
        "    n = img.shape[0]\n",
        "    print(n, \" Bands\")\n",
        "\n",
        "    # load your random forest model from the pickle file\n",
        "    clf = joblib.load(modelfile)    \n",
        "\n",
        "    # to work with SciKitLearn, we have to reshape the raster as an image\n",
        "    # this will change the shape from (bands, rows, columns) to (rows, columns, bands)\n",
        "    img = reshape_as_image(img)\n",
        "\n",
        "    # next, we have to reshape the image again into (rows * columns, bands)\n",
        "    # because that is what SciKitLearn asks for\n",
        "    new_shape = (img.shape[0] * img.shape[1], img.shape[2]) \n",
        "\n",
        "    print(\"img[:, :, :n].shape = \", img[:, :, :n].shape)\n",
        "    print(\"new_shape = \", new_shape)\n",
        "\n",
        "    img_as_array = img[:, :, :n].reshape(new_shape)   \n",
        "\n",
        "    print(\"img_as_array.shape = \", img_as_array.shape)\n",
        "\n",
        "    # classify it\n",
        "    class_prediction = clf.predict(img_as_array) \n",
        "\n",
        "    # and reshape the flattened array back to its original dimensions\n",
        "    \n",
        "    print(\"class_prediction.shape = \", class_prediction.shape)\n",
        "    print(\"img[:, :, 0].shape = \", img[:, :, 0].shape)\n",
        "\n",
        "    class_prediction = np.uint8(class_prediction.reshape(img[:, :, 0].shape))\n",
        "\n",
        "    print(class_prediction.dtype)\n",
        "    \n",
        "    # save the image as a uint8 Geotiff file\n",
        "    tmpfile = rasterio.open(outfile, 'w', driver='Gtiff', \n",
        "                            width=src.width, height=src.height,\n",
        "                            count=1, crs=src.crs, transform=src.transform, \n",
        "                            dtype=np.uint8)\n",
        "\n",
        "    tmpfile.write(class_prediction, 1)\n",
        "\n",
        "    tmpfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97mDdqiW45vc"
      },
      "source": [
        "Now we can run the classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtdEoBpyrjj1"
      },
      "source": [
        "# call our classification function\n",
        "classification(clipfile, modelfile, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i6_HOVG9ToJ"
      },
      "source": [
        "# Visualise the classified image\n",
        "We need to check the results to make sure it worked. Let's take a look.\n",
        "\n",
        "What we do differently here is that we visualise a classified raster dataset. This means we can define our own class labels (that match our training data labels) and associate them with a colour scheme.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH0PejD99Y0h"
      },
      "source": [
        "# inspired by https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/classify-plot-raster-data-in-python/\n",
        "\n",
        "# Create a list of labels to use for your legend\n",
        "class_labels = [\"Water\", \n",
        "                \"Residential\", \n",
        "                \"Industrial\", \n",
        "                \"Pasture\", \n",
        "                \"Crops\", \n",
        "                \"Bare soil\", \n",
        "                \"Forest\"]\n",
        "\n",
        "# Create a colormap from a list of colours\n",
        "# see this chart for information on available colours:\n",
        "# https://matplotlib.org/2.0.0/examples/color/named_colors.html \n",
        "colours = ['mediumblue', \n",
        "          'firebrick', \n",
        "          'red', \n",
        "          'yellowgreen', \n",
        "          'gold', \n",
        "          'saddlebrown', \n",
        "          'darkolivegreen']\n",
        "\n",
        "cmap = matplotlib.colors.ListedColormap(colours)\n",
        "\n",
        "# calculate the bin boundaries between class values, e.g. 0.5-1.5 for class 1\n",
        "class_bins = [i+0.5 for i in range(len(class_labels)+1)]\n",
        "\n",
        "# Generate a colourmap index based on discrete intervals\n",
        "norm = matplotlib.colors.BoundaryNorm(class_bins, len(colours))\n",
        "\n",
        "# Plot our classified land cover raster\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10, 5))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "imgfile = rasterio.open(outfile, 'r')\n",
        "plot.show(imgfile, ax=ax1, cmap=cmap, norm=norm)\n",
        "# set a title for the plot\n",
        "mytitle = \"My own land cover map\"\n",
        "ax1.set_title(mytitle, fontsize=12)\n",
        "imgfile.close()\n",
        "\n",
        "# We will use the Geopandas library for plotting the shapefile\n",
        "shp = gpd.read_file(trainshapefile)\n",
        "shp.plot(ax=ax1, facecolor=\"none\", edgecolor=\"black\")\n",
        "shp.plot(ax=ax2, facecolor=\"none\", edgecolor=\"black\")\n",
        "# set a title for the subplot\n",
        "mytitle = trainshapefile\n",
        "ax2.set_title(mytitle, fontsize=8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp_uvsIr5dNz"
      },
      "source": [
        "We have produced a new land cover map from multi-temporal imagery. We could now evaluate which map is more accurate using accuracy assessment techniques.\n",
        "\n",
        "The classification methodology and the workflow in these practicals can be a basis for your own satellite image processing application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd5Ej-RSM9cw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}